{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Nekhaenko/BigData1/blob/master/Untitled39.ipynb",
      "authorship_tag": "ABX9TyPMv2k9T9JSlsz7VGuSAGna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nekhaenko/BigData1/blob/master/Untitled39.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install ccxt"
      ],
      "metadata": {
        "id": "_wgCLa8nXdhC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "# import plotly.graph_objects as go\n",
        "# import pickle"
      ],
      "metadata": {
        "id": "jEZvzpZpYGGU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pth = '/content/drive/MyDrive/datasets/traders/'\n",
        "\n",
        "exchange = ccxt.bingx()\n",
        "date = pd.to_datetime('now').date()"
      ],
      "metadata": {
        "id": "DCqhklV3YM7l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exchange.load_markets()\n",
        "symbols = exchange.markets.values()\n",
        "coins = set()\n",
        "for market in symbols:\n",
        "  if market['quote'] in ['USDT'] and market['type'] == 'spot':\n",
        "    coins.update([market['symbol']])\n",
        "    # break\n",
        "\n",
        "# sorted_coins = sorted(coins)\n",
        "# print(\"Список криптовалют на BingX:\")\n",
        "# for coin in sorted_coins:\n",
        "#     print(f\"- {coin}\")\n",
        "coins = list(coins)\n",
        "coins[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZFIfNKxYUwG",
        "outputId": "00ab1b47-f486-4a70-f179-a476f4afe65b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['COQ/USDT', 'OGN/USDT', 'JUV/USDT']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{pth}tokens.json\", \"w\") as f:\n",
        "  json.dump(coins, f)"
      ],
      "metadata": {
        "id": "qsf6w22xJXrI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_to_save = {\n",
        "#     \"timestamp\": date,\n",
        "#     \"exchange\": \"BingX\",\n",
        "#     \"crypto_list\": coins\n",
        "# }\n",
        "\n",
        "# with open(f\"{pth}tokens.json\", \"w\") as f:\n",
        "#   json.dump(data_to_save, f)"
      ],
      "metadata": {
        "id": "PV9iIwStHvnJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# import json\n",
        "\n",
        "# url = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
        "# params = {\n",
        "#     \"vs_currency\": \"usd\",  # валюта сравнения\n",
        "#     \"order\": \"market_cap_desc\",  # сортировка по капитализации ▼\n",
        "#     \"per_page\": 250,  # ограничение по количеству\n",
        "#     \"sparkline\": \"False\"  # отключаем лишний побрякушпи\n",
        "# }\n",
        "\n",
        "# response = requests.get(url, params=params)\n",
        "\n",
        "# if response.status_code == 200:\n",
        "#     data = json.loads(response.text)\n",
        "#     for coin in data:\n",
        "#         print(f\"({coin['market_cap_rank']}) {coin['symbol']} | $[{coin['current_price']}] | Объем: ${f}\".format(coin['total_volume']))\n",
        "# else:\n",
        "#     print(\"Ошибка:\", response.status_code)"
      ],
      "metadata": {
        "id": "F5yA4kFqPkcK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = []\n",
        "for i in data:\n",
        "  symbols.append(i['symbol'])"
      ],
      "metadata": {
        "id": "QMbCC_9KQDMA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTPgvwSeeYb5",
        "outputId": "77b3b241-805b-4bfb-d35a-7f6cb2812ce4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['btc', 'eth', 'xrp']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{pth}popular_tokens.json\", \"w\") as f:\n",
        "  json.dump(symbols, f)"
      ],
      "metadata": {
        "id": "OGarOG9bfMHx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{pth}popular_tokens.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    symbols = json.load(f)"
      ],
      "metadata": {
        "id": "HUbDopZ8Iu0P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3PMkmrOQtx-",
        "outputId": "3c2de743-1d67-4b0d-b1a2-8d027f1c2675"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['btc',\n",
              " 'eth',\n",
              " 'xrp',\n",
              " 'usdt',\n",
              " 'bnb',\n",
              " 'sol',\n",
              " 'usdc',\n",
              " 'steth',\n",
              " 'doge',\n",
              " 'trx',\n",
              " 'ada',\n",
              " 'wsteth',\n",
              " 'wbtc',\n",
              " 'hype',\n",
              " 'sui',\n",
              " 'xlm',\n",
              " 'link',\n",
              " 'wbeth',\n",
              " 'hbar',\n",
              " 'bch']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpiDuy0RKNjj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diff(x):\n",
        "  try:\n",
        "    return round(100 - x[0]*100/x[1])\n",
        "  except:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "yYpbxanM5PKf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepeare_data(tmp):\n",
        "  SMA1 = 5\n",
        "  SMA2 = 30\n",
        "  symbol='Close'\n",
        "  tmp['SMA1'] = tmp[symbol].rolling(SMA1).mean()\n",
        "  tmp['SMA2'] = tmp[symbol].rolling(SMA2).mean()\n",
        "  tmp['diff'] = tmp[['SMA1', 'SMA2']].apply(diff, axis=1)\n",
        "  tmp['diff_shift'] = tmp['diff'].shift()\n",
        "  tmp['target'] = 0\n",
        "  tmp.loc[((tmp['diff_shift'] >= 0)&(tmp['diff'] < 0)), 'target'] = 1\n",
        "  tmp.loc[tmp['target'] == 1, 'base_price'] = tmp.loc[tmp['target'] == 1, 'Close']\n",
        "  tmp['base_price'].fillna(method = 'backfill', inplace=True)\n",
        "  tmp['base_price_bool'] = 0\n",
        "  tmp.loc[(tmp['High']> tmp['base_price']), 'base_price_bool'] = 1\n",
        "  pos_bool = False\n",
        "  id_pos = 0\n",
        "\n",
        "  for ind in reversed(tmp.index):\n",
        "      target = tmp.loc[ind, 'target']\n",
        "      if target == 1:\n",
        "        id_pos = ind\n",
        "        pos_bool = True\n",
        "\n",
        "      if pos_bool and tmp.loc[ind, 'base_price_bool'] == 0 and target == 0:\n",
        "        tmp.loc[ind, 'target'] = 1\n",
        "\n",
        "      elif tmp.loc[ind, 'base_price_bool'] == 1 and id_pos != ind:\n",
        "        pos_bool = False\n",
        "\n",
        "  tmp.drop(['base_price', 'base_price_bool', 'SMA1', 'SMA2'], axis=1, inplace=True)\n",
        "  tmp['diff_high_low'] = tmp['High'] - tmp['Low']\n",
        "  tmp['diff_high_low'] = tmp['diff_high_low']*10000\n",
        "  tmp['diff_high_low'] = tmp.diff_high_low.round()\n",
        "\n",
        "  tmp['diff_open_close'] = tmp['Open'] - tmp['Close']\n",
        "  tmp['diff_open_close'] = tmp['diff_open_close']*10000\n",
        "  tmp['diff_open_close'] = tmp['diff_open_close'].round()\n",
        "  tmp['speed'] = np.where(tmp['diff_open_close'].abs() > 0, tmp['diff_high_low']/tmp['diff_open_close'], 0)\n",
        "  # tmp['diff_open_close'] = tmp['diff_open_close'].abs()\n",
        "\n",
        "  for i in range(1, 51):\n",
        "    tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
        "    tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
        "    tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
        "\n",
        "  return tmp"
      ],
      "metadata": {
        "id": "VxtlqBE5e73X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_technical_indicators(data):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive technical indicators\n",
        "    \"\"\"\n",
        "\n",
        "    # RSI (Relative Strength Index)\n",
        "    # data['RSI_14'] = calculate_rsi(data['close'], 14)\n",
        "\n",
        "    # MACD\n",
        "    data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
        "    data['MACD_signal'] = data['MACD'].ewm(span=9).mean()\n",
        "    data['MACD_histogram'] = data['MACD'] - data['MACD_signal']\n",
        "\n",
        "    # Bollinger Bands\n",
        "    data['BB_middle'] = data['Close'].rolling(window=20).mean()\n",
        "    data['BB_upper'] = data['BB_middle'] + (data['Close'].rolling(window=20).std() * 2)\n",
        "    data['BB_lower'] = data['BB_middle'] - (data['Close'].rolling(window=20).std() * 2)\n",
        "\n",
        "    # Volatility Measures\n",
        "    data['volatility_7'] = data['Close'].rolling(window=7).std()\n",
        "    data['volatility_14'] = data['Close'].rolling(window=14).std()\n",
        "    data['volatility_21'] = data['Close'].rolling(window=21).std()\n",
        "\n",
        "    # Price-based Features\n",
        "    data['daily_return'] = data['Close'].pct_change()\n",
        "    data['high_low_ratio'] = data['High'] / data['Low']\n",
        "    data['close_open_ratio'] = data['Close'] / data['Open']\n",
        "\n",
        "    # Volume-based Features\n",
        "    data['volume_ma_7'] = data['Volume'].rolling(window=7).mean()\n",
        "    data['volume_ratio'] = data['Volume'] / data['volume_ma_7']\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "KnrxZjS3XcSa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for symbol in symbols[3:5]:\n",
        "  if symbol.find('usd') < 0:\n",
        "    if symbol.find('/USDT')>=0:\n",
        "      print()\n",
        "    else:\n",
        "      symbol = f'{symbol.upper()}/USDT'\n",
        "\n",
        "    print(symbol)\n",
        "\n",
        "    data = exchange.fetchOHLCV(symbol = symbol,\n",
        "                              timeframe = \"1d\",\n",
        "                              limit = 2000)\n",
        "    df = pd.DataFrame(data)\n",
        "    df.columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "    df.Date = pd.to_datetime(df.Date, unit = \"ms\")\n",
        "    df.set_index(\"Date\", inplace = True)\n",
        "    symbol = symbol.replace('/', '_')\n",
        "    pthc = f'{pth}{symbol}_{date}.csv'\n",
        "    df.to_csv(pthc)\n",
        "    df = prepeare_data(df)\n",
        "    df = calculate_technical_indicators(df)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqYyErqUYSYf",
        "outputId": "6a008885-db40-4f08-9d77-f313fb9fbfd2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BNB/USDT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2329801253.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  return round(100 - x[0]*100/x[1])\n",
            "/tmp/ipython-input-1270689435.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  tmp['base_price'].fillna(method = 'backfill', inplace=True)\n",
            "/tmp/ipython-input-1270689435.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  tmp['base_price'].fillna(method = 'backfill', inplace=True)\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-1270689435.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'daily_return_{i}'] = tmp['Close'].pct_change(i)\n",
            "/tmp/ipython-input-1270689435.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'SMA_{i}'] = tmp['Close'].rolling(i).mean()\n",
            "/tmp/ipython-input-1270689435.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  tmp[f'EMA_{i}'] = tmp['Close'].ewm(span=i).mean()\n",
            "/tmp/ipython-input-2094253980.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
            "/tmp/ipython-input-2094253980.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['MACD_signal'] = data['MACD'].ewm(span=9).mean()\n",
            "/tmp/ipython-input-2094253980.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['MACD_histogram'] = data['MACD'] - data['MACD_signal']\n",
            "/tmp/ipython-input-2094253980.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['BB_middle'] = data['Close'].rolling(window=20).mean()\n",
            "/tmp/ipython-input-2094253980.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['BB_upper'] = data['BB_middle'] + (data['Close'].rolling(window=20).std() * 2)\n",
            "/tmp/ipython-input-2094253980.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['BB_lower'] = data['BB_middle'] - (data['Close'].rolling(window=20).std() * 2)\n",
            "/tmp/ipython-input-2094253980.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['volatility_7'] = data['Close'].rolling(window=7).std()\n",
            "/tmp/ipython-input-2094253980.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['volatility_14'] = data['Close'].rolling(window=14).std()\n",
            "/tmp/ipython-input-2094253980.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['volatility_21'] = data['Close'].rolling(window=21).std()\n",
            "/tmp/ipython-input-2094253980.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['daily_return'] = data['Close'].pct_change()\n",
            "/tmp/ipython-input-2094253980.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['high_low_ratio'] = data['High'] / data['Low']\n",
            "/tmp/ipython-input-2094253980.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['close_open_ratio'] = data['Close'] / data['Open']\n",
            "/tmp/ipython-input-2094253980.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['volume_ma_7'] = data['Volume'].rolling(window=7).mean()\n",
            "/tmp/ipython-input-2094253980.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  data['volume_ratio'] = data['Volume'] / data['volume_ma_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "ARDzkypTiS1d",
        "outputId": "ef88a241-4142-4951-ada4-bd43475cab99"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Open    High     Low   Close    Volume  diff  \\\n",
              "Date                                                                  \n",
              "2025-07-28 16:00:00  836.17  841.09  802.00  806.66  6247.777   -12   \n",
              "2025-07-29 16:00:00  805.22  815.57  779.00  790.78  6529.226   -12   \n",
              "2025-07-30 16:00:00  790.87  814.64  766.41  796.44  4394.576   -12   \n",
              "\n",
              "                     diff_shift  target  diff_high_low  diff_open_close  ...  \\\n",
              "Date                                                                     ...   \n",
              "2025-07-28 16:00:00       -12.0       0       390900.0         295100.0  ...   \n",
              "2025-07-29 16:00:00       -12.0       0       365700.0         144400.0  ...   \n",
              "2025-07-30 16:00:00       -12.0       0       482300.0         -55700.0  ...   \n",
              "\n",
              "                       BB_upper    BB_lower  volatility_7  volatility_14  \\\n",
              "Date                                                                       \n",
              "2025-07-28 16:00:00  843.188096  641.830904     24.728521      37.531076   \n",
              "2025-07-29 16:00:00  845.101305  652.179695     24.375359      32.481088   \n",
              "2025-07-30 16:00:00  848.263507  659.936493     23.065947      29.129333   \n",
              "\n",
              "                     volatility_21  daily_return  high_low_ratio  \\\n",
              "Date                                                               \n",
              "2025-07-28 16:00:00      52.082224     -0.035292        1.048741   \n",
              "2025-07-29 16:00:00      50.182637     -0.019686        1.046945   \n",
              "2025-07-30 16:00:00      48.152495      0.007157        1.062930   \n",
              "\n",
              "                     close_open_ratio  volume_ma_7  volume_ratio  \n",
              "Date                                                              \n",
              "2025-07-28 16:00:00          0.964708  6325.338286      0.987738  \n",
              "2025-07-29 16:00:00          0.982067  5856.513000      1.114866  \n",
              "2025-07-30 16:00:00          1.007043  5531.744857      0.794429  \n",
              "\n",
              "[3 rows x 175 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3e89535-d43a-4046-b04f-0ccf6881fa85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>diff</th>\n",
              "      <th>diff_shift</th>\n",
              "      <th>target</th>\n",
              "      <th>diff_high_low</th>\n",
              "      <th>diff_open_close</th>\n",
              "      <th>...</th>\n",
              "      <th>BB_upper</th>\n",
              "      <th>BB_lower</th>\n",
              "      <th>volatility_7</th>\n",
              "      <th>volatility_14</th>\n",
              "      <th>volatility_21</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>high_low_ratio</th>\n",
              "      <th>close_open_ratio</th>\n",
              "      <th>volume_ma_7</th>\n",
              "      <th>volume_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-07-28 16:00:00</th>\n",
              "      <td>836.17</td>\n",
              "      <td>841.09</td>\n",
              "      <td>802.00</td>\n",
              "      <td>806.66</td>\n",
              "      <td>6247.777</td>\n",
              "      <td>-12</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>390900.0</td>\n",
              "      <td>295100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>843.188096</td>\n",
              "      <td>641.830904</td>\n",
              "      <td>24.728521</td>\n",
              "      <td>37.531076</td>\n",
              "      <td>52.082224</td>\n",
              "      <td>-0.035292</td>\n",
              "      <td>1.048741</td>\n",
              "      <td>0.964708</td>\n",
              "      <td>6325.338286</td>\n",
              "      <td>0.987738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-29 16:00:00</th>\n",
              "      <td>805.22</td>\n",
              "      <td>815.57</td>\n",
              "      <td>779.00</td>\n",
              "      <td>790.78</td>\n",
              "      <td>6529.226</td>\n",
              "      <td>-12</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>365700.0</td>\n",
              "      <td>144400.0</td>\n",
              "      <td>...</td>\n",
              "      <td>845.101305</td>\n",
              "      <td>652.179695</td>\n",
              "      <td>24.375359</td>\n",
              "      <td>32.481088</td>\n",
              "      <td>50.182637</td>\n",
              "      <td>-0.019686</td>\n",
              "      <td>1.046945</td>\n",
              "      <td>0.982067</td>\n",
              "      <td>5856.513000</td>\n",
              "      <td>1.114866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-30 16:00:00</th>\n",
              "      <td>790.87</td>\n",
              "      <td>814.64</td>\n",
              "      <td>766.41</td>\n",
              "      <td>796.44</td>\n",
              "      <td>4394.576</td>\n",
              "      <td>-12</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>482300.0</td>\n",
              "      <td>-55700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>848.263507</td>\n",
              "      <td>659.936493</td>\n",
              "      <td>23.065947</td>\n",
              "      <td>29.129333</td>\n",
              "      <td>48.152495</td>\n",
              "      <td>0.007157</td>\n",
              "      <td>1.062930</td>\n",
              "      <td>1.007043</td>\n",
              "      <td>5531.744857</td>\n",
              "      <td>0.794429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 175 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3e89535-d43a-4046-b04f-0ccf6881fa85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3e89535-d43a-4046-b04f-0ccf6881fa85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3e89535-d43a-4046-b04f-0ccf6881fa85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d0ddcc5-5e07-4042-ba84-a7d4faa72fbb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d0ddcc5-5e07-4042-ba84-a7d4faa72fbb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d0ddcc5-5e07-4042-ba84-a7d4faa72fbb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts('target')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9dPvYc1ZiwJD",
        "outputId": "504c675f-47a7-4c5e-a12f-fbc4e0532c25"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    826\n",
              "1    174\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "edGw_s2qmEMD"
      },
      "outputs": [],
      "source": [
        "# def calculate_cross_asset_features(all_data):\n",
        "#     \"\"\"\n",
        "#     Calculate features that compare assets or market-wide indicators\n",
        "#     \"\"\"\n",
        "#     # Bitcoin dominance effect\n",
        "#     btc_returns = all_data['BTC']['daily_return']\n",
        "\n",
        "#     for symbol in all_data.keys():\n",
        "#         if symbol != 'BTC':\n",
        "#             # Correlation with Bitcoin\n",
        "#             all_data[symbol]['btc_correlation'] = all_data[symbol]['daily_return'].rolling(window=30).corr(btc_returns)\n",
        "\n",
        "#             # Relative strength vs Bitcoin\n",
        "#             all_data[symbol]['relative_strength_btc'] = all_data[symbol]['close'] / all_data['BTC']['close']\n",
        "\n",
        "#     # Market cap weighted average returns\n",
        "#     market_avg_return = calculate_market_weighted_return(all_data)\n",
        "\n",
        "#     for symbol in all_data.keys():\n",
        "#         all_data[symbol]['market_relative_return'] = all_data[symbol]['daily_return'] - market_avg_return\n",
        "\n",
        "#     return all_data\n",
        "\n",
        "\n",
        "# def generate_labels(data, lookforward_days=7, min_gain=0.05, max_drawdown=0.03):\n",
        "#     \"\"\"\n",
        "#     Generate binary labels for entry points\n",
        "#     \"\"\"\n",
        "#     labels = []\n",
        "\n",
        "#     for i in range(len(data) - lookforward_days):\n",
        "#         entry_price = data.iloc[i]['close']\n",
        "#         future_prices = data.iloc[i+1:i+lookforward_days+1]['close']\n",
        "#         future_lows = data.iloc[i+1:i+lookforward_days+1]['low']\n",
        "\n",
        "#         # Check for profitable opportunity\n",
        "#         max_gain = (future_prices.max() - entry_price) / entry_price\n",
        "#         max_drawdown = (entry_price - future_lows.min()) / entry_price\n",
        "\n",
        "#         # Label as positive if conditions met\n",
        "#         if max_gain >= min_gain and max_drawdown <= max_drawdown:\n",
        "#             labels.append(1)\n",
        "#         else:\n",
        "#             labels.append(0)\n",
        "\n",
        "#     return labels\n",
        "\n",
        "# 4.3 Advanced Labeling Strategy\n",
        "\n",
        "# Signal Strength: Weight labels based on magnitude of opportunity\n",
        "# Risk-Adjusted Returns: Consider Sharpe ratio for labeling\n",
        "# Market Regime: Adjust criteria based on bull/bear market conditions\n",
        "\n",
        "# 5. Data Normalization and Scaling\n",
        "# 5.1 Normalization Methods\n",
        "# def normalize_features(data):\n",
        "#     \"\"\"\n",
        "#     Apply appropriate normalization to different feature types\n",
        "#     \"\"\"\n",
        "#     # Price-based features: Log transformation\n",
        "#     price_features = ['close', 'open', 'high', 'low', 'MA_7', 'MA_14', 'MA_21', 'MA_50']\n",
        "#     for feature in price_features:\n",
        "#         data[f'{feature}_log'] = np.log(data[feature])\n",
        "\n",
        "#     # Ratio features: StandardScaler\n",
        "#     ratio_features = ['daily_return', 'volume_ratio', 'high_low_ratio']\n",
        "#     scaler = StandardScaler()\n",
        "#     data[ratio_features] = scaler.fit_transform(data[ratio_features])\n",
        "\n",
        "#     # Bounded indicators: MinMaxScaler\n",
        "#     bounded_features = ['RSI_14']\n",
        "#     minmax_scaler = MinMaxScaler()\n",
        "#     data[bounded_features] = minmax_scaler.fit_transform(data[bounded_features])\n",
        "\n",
        "#     return data\n",
        "\n",
        "# 5.2 Rolling Window Normalization\n",
        "\n",
        "# Look-back Period: 252 days (1 year)\n",
        "# Method: Z-score normalization using rolling mean and std\n",
        "# Prevents Data Leakage: Only uses historical data for normalization\n",
        "\n",
        "# 6. Handling Class Imbalance\n",
        "# 6.1 Imbalance Assessment\n",
        "# def assess_class_imbalance(labels):\n",
        "#     \"\"\"\n",
        "#     Analyze class distribution across all assets\n",
        "#     \"\"\"\n",
        "#     positive_ratio = sum(labels) / len(labels)\n",
        "#     print(f\"Positive class ratio: {positive_ratio:.3f}\")\n",
        "\n",
        "#     if positive_ratio < 0.1 or positive_ratio > 0.9:\n",
        "#         print(\"Severe class imbalance detected\")\n",
        "#         return True\n",
        "#     return False\n",
        "\n",
        "# 6.2 Resampling Strategies\n",
        "\n",
        "# SMOTE: Synthetic Minority Oversampling Technique for time series\n",
        "# Random Undersampling: Reduce majority class while preserving temporal structure\n",
        "# Ensemble Methods: Use class-weighted algorithms\n",
        "# Threshold Adjustment: Optimize classification threshold post-training\n",
        "\n",
        "# 6.3 Implementation\n",
        "# def handle_class_imbalance(X, y, method='smote'):\n",
        "#     \"\"\"\n",
        "#     Address class imbalance in the dataset\n",
        "#     \"\"\"\n",
        "#     if method == 'smote':\n",
        "#         smote = SMOTE(random_state=42)\n",
        "#         X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "#     elif method == 'undersample':\n",
        "#         undersampler = RandomUnderSampler(random_state=42)\n",
        "#         X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "#     return X_resampled, y_resampled\n",
        "\n",
        "# 7. Data Splitting Strategy\n",
        "# 7.1 Time-Series Aware Splitting\n",
        "# def create_train_val_test_split(data, train_ratio=0.7, val_ratio=0.15):\n",
        "#     \"\"\"\n",
        "#     Create chronological splits for time series data\n",
        "#     \"\"\"\n",
        "#     n_samples = len(data)\n",
        "\n",
        "#     # Chronological split points\n",
        "#     train_end = int(n_samples * train_ratio)\n",
        "#     val_end = int(n_samples * (train_ratio + val_ratio))\n",
        "\n",
        "#     train_data = data[:train_end]\n",
        "#     val_data = data[train_end:val_end]\n",
        "#     test_data = data[val_end:]\n",
        "\n",
        "#     return train_data, val_data, test_data\n",
        "\n",
        "# 7.2 Cross-Validation Strategy\n",
        "\n",
        "# Time Series CV: Use TimeSeriesSplit with 5 folds\n",
        "# Walk-Forward Validation: Simulate realistic trading conditions\n",
        "# Asset-Based CV: Validate across different cryptocurrencies\n",
        "\n",
        "# 8. Feature Selection and Dimensionality Reduction\n",
        "# 8.1 Feature Importance Analysis\n",
        "# def select_features(X, y, method='rf_importance'):\n",
        "#     \"\"\"\n",
        "#     Select most informative features\n",
        "#     \"\"\"\n",
        "#     if method == 'rf_importance':\n",
        "#         rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#         rf.fit(X, y)\n",
        "#         feature_importance = rf.feature_importances_\n",
        "\n",
        "#         # Select top 50% features\n",
        "#         top_features = np.argsort(feature_importance)[-int(len(feature_importance)*0.5):]\n",
        "#         return top_features\n",
        "\n",
        "#     elif method == 'mutual_info':\n",
        "#         mi_scores = mutual_info_classif(X, y)\n",
        "#         top_features = np.argsort(mi_scores)[-int(len(mi_scores)*0.5):]\n",
        "#         return top_features\n",
        "\n",
        "# 8.2 Correlation Analysis\n",
        "\n",
        "# Remove Highly Correlated Features: Threshold > 0.95\n",
        "# Variance Inflation Factor: Address multicollinearity\n",
        "# Principal Component Analysis: Optional dimensionality reduction\n",
        "\n",
        "# 9. Dataset Validation and Quality Assurance\n",
        "# 9.1 Data Integrity Checks\n",
        "# def validate_dataset(X, y):\n",
        "#     \"\"\"\n",
        "#     Comprehensive dataset validation\n",
        "#     \"\"\"\n",
        "#     checks = {\n",
        "#         'no_data_leakage': check_temporal_consistency(X),\n",
        "#         'feature_stability': check_feature_distributions(X),\n",
        "#         'label_quality': validate_label_logic(y),\n",
        "#         'missing_values': check_missing_data(X),\n",
        "#         'outliers': detect_statistical_outliers(X)\n",
        "#     }\n",
        "\n",
        "#     return checks\n",
        "\n",
        "# 9.2 Performance Benchmarks\n",
        "\n",
        "# Random Baseline: 50% accuracy expectation\n",
        "# Buy-and-Hold Strategy: Compare against passive investment\n",
        "# Technical Analysis Baseline: Simple moving average crossover\n",
        "\n",
        "# 10. Model Training Optimization\n",
        "# 10.1 Algorithm Selection\n",
        "\n",
        "# Gradient Boosting: XGBoost, LightGBM for tabular data\n",
        "# Random Forest: Robust to overfitting\n",
        "# Neural Networks: LSTM for sequence modeling\n",
        "# Ensemble Methods: Combine multiple algorithms\n",
        "\n",
        "# 10.2 Hyperparameter Optimization\n",
        "# def optimize_hyperparameters(X_train, y_train, X_val, y_val):\n",
        "#     \"\"\"\n",
        "#     Optimize model hyperparameters using validation set\n",
        "#     \"\"\"\n",
        "#     from optuna import create_study\n",
        "\n",
        "#     def objective(trial):\n",
        "#         params = {\n",
        "#             'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "#             'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "#             'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "#             'subsample': trial.suggest_float('subsample', 0.8, 1.0)\n",
        "#         }\n",
        "\n",
        "#         model = XGBClassifier(**params)\n",
        "#         model.fit(X_train, y_train)\n",
        "#         y_pred = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "#         return roc_auc_score(y_val, y_pred)\n",
        "\n",
        "#     study = create_study(direction='maximize')\n",
        "#     study.optimize(objective, n_trials=100)\n",
        "\n",
        "#     return study.best_params\n",
        "\n",
        "# 11. Evaluation Metrics and Profitability Assessment\n",
        "# 11.1 Classification Metrics\n",
        "\n",
        "# Precision: Minimize false positives (bad entry signals)\n",
        "# Recall: Capture profitable opportunities\n",
        "# F1-Score: Balance precision and recall\n",
        "# AUC-ROC: Model discrimination ability\n",
        "\n",
        "# 11.2 Trading-Specific Metrics\n",
        "# def calculate_trading_metrics(predictions, actual_returns):\n",
        "#     \"\"\"\n",
        "#     Calculate trading-specific performance metrics\n",
        "#     \"\"\"\n",
        "#     # Sharpe Ratio\n",
        "#     sharpe = np.mean(actual_returns) / np.std(actual_returns) * np.sqrt(252)\n",
        "\n",
        "#     # Maximum Drawdown\n",
        "#     cumulative_returns = np.cumprod(1 + actual_returns)\n",
        "#     max_drawdown = np.max(np.maximum.accumulate(cumulative_returns) - cumulative_returns)\n",
        "\n",
        "#     # Win Rate\n",
        "#     win_rate = np.mean(actual_returns > 0)\n",
        "\n",
        "#     # Profit Factor\n",
        "#     gross_profit = np.sum(actual_returns[actual_returns > 0])\n",
        "#     gross_loss = np.sum(np.abs(actual_returns[actual_returns < 0]))\n",
        "#     profit_factor = gross_profit / gross_loss if gross_loss > 0 else np.inf\n",
        "\n",
        "#     return {\n",
        "#         'sharpe_ratio': sharpe,\n",
        "#         'max_drawdown': max_drawdown,\n",
        "#         'win_rate': win_rate,\n",
        "#         'profit_factor': profit_factor\n",
        "#     }\n",
        "\n",
        "# 12. Production Pipeline\n",
        "# 12.1 Real-time Data Pipeline\n",
        "# def create_production_pipeline():\n",
        "#     \"\"\"\n",
        "#     Create real-time prediction pipeline\n",
        "#     \"\"\"\n",
        "#     # Data ingestion\n",
        "#     data_pipeline = Pipeline([\n",
        "#         ('collector', DataCollector()),\n",
        "#         ('cleaner', DataCleaner()),\n",
        "#         ('feature_engineer', FeatureEngineer()),\n",
        "#         ('normalizer', DataNormalizer()),\n",
        "#         ('predictor', TrainedModel())\n",
        "#     ])\n",
        "\n",
        "#     return data_pipeline\n",
        "\n",
        "# 12.2 Model Monitoring\n",
        "\n",
        "# Performance Drift Detection: Monitor prediction accuracy over time\n",
        "# Data Drift Detection: Identify changes in input distributions\n",
        "# Retraining Triggers: Automated model updates\n",
        "# A/B Testing: Compare model versions\n",
        "\n",
        "# 13. Risk Management Integration\n",
        "# 13.1 Position Sizing\n",
        "\n",
        "# Kelly Criterion: Optimal position sizing based on win rate and odds\n",
        "# Risk Parity: Equal risk contribution across positions\n",
        "# Volatility Targeting: Adjust position size based on expected volatility\n",
        "\n",
        "# 13.2 Portfolio-Level Considerations\n",
        "\n",
        "# Correlation Limits: Avoid over-concentration in correlated assets\n",
        "# Sector Exposure: Diversify across different crypto sectors\n",
        "# Liquidity Requirements: Ensure sufficient trading volume\n",
        "\n",
        "# 14. Implementation Checklist\n",
        "# 14.1 Data Collection\n",
        "\n",
        "# [ ] Set up multiple data source APIs\n",
        "# [ ] Implement data validation and quality checks\n",
        "# [ ] Create automated data collection pipeline\n",
        "# [ ] Set up data storage and versioning\n",
        "\n",
        "# 14.2 Feature Engineering\n",
        "\n",
        "# [ ] Implement all technical indicators\n",
        "# [ ] Create cross-asset features\n",
        "# [ ] Test feature stability across time periods\n",
        "# [ ] Validate feature importance\n",
        "\n",
        "# 14.3 Model Development\n",
        "\n",
        "# [ ] Implement multiple algorithms\n",
        "# [ ] Set up hyperparameter optimization\n",
        "# [ ] Create ensemble methods\n",
        "# [ ] Validate using walk-forward analysis\n",
        "\n",
        "# 14.4 Production Deployment\n",
        "\n",
        "# [ ] Create real-time prediction pipeline\n",
        "# [ ] Implement monitoring and alerting\n",
        "# [ ] Set up A/B testing framework\n",
        "# [ ] Create risk management controls\n",
        "\n",
        "# Conclusion\n",
        "# This comprehensive algorithm provides a robust framework for creating a high-quality cryptocurrency trading dataset. The key to success lies in careful attention to data quality, feature engineering, and proper validation techniques that respect the temporal nature of financial data. Regular monitoring and retraining ensure the model remains effective as market conditions evolve."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U lightautoml"
      ],
      "metadata": {
        "id": "YKctesW3qa2R"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import requests\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML#, TabularUtilizedAutoML\n",
        "from lightautoml.tasks import Task\n",
        "from lightautoml.report.report_deco import ReportDeco#, ReportDecoUtilized\n",
        "# from lightautoml.addons.tabular_interpretation import SSWARM"
      ],
      "metadata": {
        "id": "kSe1Zbgqimjm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_THREADS = 4\n",
        "N_FOLDS = 5\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "TIMEOUT = 3600\n",
        "TARGET_NAME = 'target'\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.set_num_threads(N_THREADS)"
      ],
      "metadata": {
        "id": "E8_tV_sDiqsb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(\n",
        "    df,\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=df[TARGET_NAME],\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f'Data is splitted. Parts sizes: train_data = {train_data.shape}, test_data = {test_data.shape}')\n",
        "\n",
        "# train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeKz6F_ZknvT",
        "outputId": "efc1307f-59fc-4ae9-d718-4a3946728496"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is splitted. Parts sizes: train_data = (800, 175), test_data = (200, 175)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task('binary')\n",
        "roles = {'target': TARGET_NAME,\n",
        "         'drop': ['Date']\n",
        "         }\n",
        "\n",
        "automl = TabularAutoML(\n",
        "    task = task,\n",
        "    timeout = TIMEOUT,\n",
        "    cpu_limit = N_THREADS,\n",
        "    reader_params = {'n_jobs': N_THREADS,\n",
        "                     'cv': N_FOLDS,\n",
        "                     'random_state': RANDOM_STATE},\n",
        ")\n",
        "\n",
        "out_of_fold_predictions = automl.fit_predict(train_data, roles = roles,\n",
        "                                             verbose = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhAVestdkqMY",
        "outputId": "6ae8fb50-ce0a-47cb-b481-edc4f1acc8bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] - time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 3600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] - CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 4 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:13] \u001b[1mTrain data shape: (800, 175)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (800, 175)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:26] Layer \u001b[1m1\u001b[0m train process start. Time left 3586.86 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 3586.86 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0, 1, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204], 'embed_sizes': array([27, 29, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11], dtype=int32), 'data_size': 380}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:26] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7259816207184628\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7582846003898636\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8008911166805903\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8710665552770815\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.886661097187413\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9108883319409635\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9170147591200223\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9392926761347813\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9448621553884711\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9515455304928989\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9534948482316903\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.9562795878585353\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.9562795878585352\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = 0.9562795878585353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:32] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6314935064935064\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6726190476190477\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7088744588744589\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8198051948051949\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8398268398268399\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.8706709956709956\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.8831168831168831\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9061147186147186\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9136904761904763\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9266774891774893\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9307359307359307\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.9347943722943723\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.9361471861471861\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = 0.9375\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 100 score = 0.9375\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 500 score = 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:36] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8295454545454546\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8503787878787878\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8603896103896104\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.8614718614718615\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8704004329004329\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9053030303030303\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9242424242424243\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9548160173160174\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9602272727272727\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9586038961038961\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9575216450216449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:39] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6658549783549783\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7034632034632035\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7637987012987013\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.849025974025974\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8687770562770563\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9147727272727273\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9361471861471862\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9650974025974026\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.9705086580086579\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9691558441558441\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9675324675324675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:44] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.70508658008658\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7416125541125541\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7946428571428572\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.876082251082251\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.8971861471861472\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.9234307359307359\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.9318181818181818\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.05 score = 0.9450757575757576\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.1 score = 0.950487012987013\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.5 score = 0.9567099567099568\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1 score = 0.9588744588744589\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5 score = 0.95995670995671\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 10 score = 0.9610389610389611\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 50 score = 0.9610389610389611\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 100 score = 0.95995670995671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:48] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9412052808585204\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9412052808585204\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:48] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:48] Time left 3564.14 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 3564.14 secs\n",
            "\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.963798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.980507\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[463]\tvalid's auc: 0.993038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:53] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:10:53] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.972153\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.97995\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.98719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1210]\tvalid's auc: 0.99081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:02] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.939123\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.944805\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.952381\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.953734\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.952381\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[396]\tvalid's auc: 0.955357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:05] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.974567\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.981061\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.984037\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.987284\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.987554\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.988636\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.989177\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.989448\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.99026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.99026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[898]\tvalid's auc: 0.99026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:13] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.965368\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.972403\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.976732\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.978896\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.980519\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.981061\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.981331\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.981061\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[633]\tvalid's auc: 0.981872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:17] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.945076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.967532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.973485\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.975108\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.976732\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.97619\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[468]\tvalid's auc: 0.977002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9802131063681581\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9802131063681581\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:19] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:11:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-3ebaa512-cace-4d0b-a08d-4b19a2eaaa37\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979671\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.984684\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[662]\tvalid's auc: 0.992481\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.9924812030075187 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.9924812030075187.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.9924812030075187 in 0:00:10.170300\n",
            "Optimization Progress:   1%|          | 1/101 [00:10<16:59, 10.19s/it, best_trial=0, best_value=0.992]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.964634\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.974659\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.977444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.981899\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.983292\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.986912\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[927]\tvalid's auc: 0.988861\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.9888610414926204 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 0 with value: 0.9924812030075187.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.9888610414926204 in 0:00:04.317710\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:14<11:08,  6.75s/it, best_trial=0, best_value=0.992]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.962963\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[690]\tvalid's auc: 0.99276\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.9927596769702034 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 2 with value: 0.9927596769702034.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored 0.9927596769702034 in 0:00:09.955947\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:24<13:25,  8.22s/it, best_trial=2, best_value=0.993]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.980228\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[664]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.9938735728209414 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 3 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored 0.9938735728209414 in 0:00:07.467242\n",
            "Optimization Progress:   4%|▍         | 4/101 [00:31<12:49,  7.93s/it, best_trial=3, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.971317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.981342\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[453]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 3 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored 0.9933166248955723 in 0:00:07.003468\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:39<12:10,  7.60s/it, best_trial=3, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.920913\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.933445\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.940685\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.945419\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.94709\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.949318\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.950989\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.950432\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.951824\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.952102\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.953773\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.953216\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1071]\tvalid's auc: 0.954052\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.9537733221943747 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 3 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored 0.9537733221943747 in 0:00:01.766269\n",
            "Optimization Progress:   6%|▌         | 6/101 [00:40<08:54,  5.63s/it, best_trial=3, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.985798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[902]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.9941520467836258 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 6 with value: 0.9941520467836258.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored 0.9941520467836258 in 0:00:10.584535\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:51<11:21,  7.26s/it, best_trial=6, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.975773\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[450]\tvalid's auc: 0.994431\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.9944305207463102 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 7 with value: 0.9944305207463102.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored 0.9944305207463102 in 0:00:03.080783\n",
            "Optimization Progress:   8%|▊         | 8/101 [00:54<09:11,  5.93s/it, best_trial=7, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.964912\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.968254\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.970203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.974937\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.978279\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.982456\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.983013\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.983849\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.984405\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.984405\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[927]\tvalid's auc: 0.984684\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.984683932052353 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 7 with value: 0.9944305207463102.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored 0.984683932052353 in 0:00:03.308284\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:57<07:50,  5.12s/it, best_trial=7, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.965748\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.978558\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.986076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[776]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 7 with value: 0.9944305207463102.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored 0.9933166248955723 in 0:00:09.811743\n",
            "Optimization Progress:  10%|▉         | 10/101 [01:07<09:58,  6.57s/it, best_trial=7, best_value=0.994]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.985519\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1101]\tvalid's auc: 0.994709\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.9947089947089947 and parameters: {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527} scored 0.9947089947089947 in 0:00:06.174259\n",
            "Optimization Progress:  11%|█         | 11/101 [01:13<09:41,  6.46s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.990253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[692]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.5075634079566923, 'num_leaves': 165, 'bagging_fraction': 0.6795146156302498, 'min_sum_hessian_in_leaf': 0.026738277166992196, 'reg_alpha': 0.0015258645761591619, 'reg_lambda': 0.01881061891210943}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5075634079566923, 'num_leaves': 165, 'bagging_fraction': 0.6795146156302498, 'min_sum_hessian_in_leaf': 0.026738277166992196, 'reg_alpha': 0.0015258645761591619, 'reg_lambda': 0.01881061891210943} scored 0.9933166248955723 in 0:00:07.525783\n",
            "Optimization Progress:  12%|█▏        | 12/101 [01:21<10:04,  6.79s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.975494\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.984127\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[631]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.5962024646862834, 'num_leaves': 129, 'bagging_fraction': 0.6794216628122437, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.0437281057923299, 'reg_lambda': 0.008452229729634516}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5962024646862834, 'num_leaves': 129, 'bagging_fraction': 0.6794216628122437, 'min_sum_hessian_in_leaf': 0.01875620628228737, 'reg_alpha': 0.0437281057923299, 'reg_lambda': 0.008452229729634516} scored 0.9933166248955723 in 0:00:04.315512\n",
            "Optimization Progress:  13%|█▎        | 13/101 [01:25<08:52,  6.05s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.990253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[885]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.580632857909944, 'num_leaves': 175, 'bagging_fraction': 0.6931449938963745, 'min_sum_hessian_in_leaf': 0.0012748888933395554, 'reg_alpha': 7.743660314424457e-05, 'reg_lambda': 0.004387238736364167}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.580632857909944, 'num_leaves': 175, 'bagging_fraction': 0.6931449938963745, 'min_sum_hessian_in_leaf': 0.0012748888933395554, 'reg_alpha': 7.743660314424457e-05, 'reg_lambda': 0.004387238736364167} scored 0.9933166248955723 in 0:00:09.066154\n",
            "Optimization Progress:  14%|█▍        | 14/101 [01:34<10:06,  6.97s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[755]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.9938735728209412 and parameters: {'feature_fraction': 0.6050778051161564, 'num_leaves': 117, 'bagging_fraction': 0.7406442464830113, 'min_sum_hessian_in_leaf': 0.49597135657371333, 'reg_alpha': 0.07389181849439323, 'reg_lambda': 3.806966588951351e-05}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.6050778051161564, 'num_leaves': 117, 'bagging_fraction': 0.7406442464830113, 'min_sum_hessian_in_leaf': 0.49597135657371333, 'reg_alpha': 0.07389181849439323, 'reg_lambda': 3.806966588951351e-05} scored 0.9938735728209412 in 0:00:04.356241\n",
            "Optimization Progress:  15%|█▍        | 15/101 [01:39<08:52,  6.19s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.956558\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.973545\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.980507\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.983013\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.985798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.985519\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[708]\tvalid's auc: 0.986076\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.9860763018657756 and parameters: {'feature_fraction': 0.9996812193207756, 'num_leaves': 185, 'bagging_fraction': 0.6223441463224709, 'min_sum_hessian_in_leaf': 3.113484383311032, 'reg_alpha': 4.150722101207275e-05, 'reg_lambda': 0.23706626312372373}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 185, 'bagging_fraction': 0.6223441463224709, 'min_sum_hessian_in_leaf': 3.113484383311032, 'reg_alpha': 4.150722101207275e-05, 'reg_lambda': 0.23706626312372373} scored 0.9860763018657756 in 0:00:06.324780\n",
            "Optimization Progress:  16%|█▌        | 16/101 [01:45<08:50,  6.24s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.994709\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.994709\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[631]\tvalid's auc: 0.994709\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.9947089947089947 and parameters: {'feature_fraction': 0.5065701578589041, 'num_leaves': 153, 'bagging_fraction': 0.7382891993530122, 'min_sum_hessian_in_leaf': 0.1341831353198184, 'reg_alpha': 0.012787488060337839, 'reg_lambda': 0.0006027209302579824}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 153, 'bagging_fraction': 0.7382891993530122, 'min_sum_hessian_in_leaf': 0.1341831353198184, 'reg_alpha': 0.012787488060337839, 'reg_lambda': 0.0006027209302579824} scored 0.9947089947089947 in 0:00:04.721418\n",
            "Optimization Progress:  17%|█▋        | 17/101 [01:50<08:06,  5.79s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.983849\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986633\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[752]\tvalid's auc: 0.99276\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.9927596769702032 and parameters: {'feature_fraction': 0.6436011536417534, 'num_leaves': 153, 'bagging_fraction': 0.9102361265933461, 'min_sum_hessian_in_leaf': 0.12233219819109843, 'reg_alpha': 0.1201298254197091, 'reg_lambda': 3.901069568054144e-06}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6436011536417534, 'num_leaves': 153, 'bagging_fraction': 0.9102361265933461, 'min_sum_hessian_in_leaf': 0.12233219819109843, 'reg_alpha': 0.1201298254197091, 'reg_lambda': 3.901069568054144e-06} scored 0.9927596769702032 in 0:00:07.821242\n",
            "Optimization Progress:  18%|█▊        | 18/101 [01:58<08:52,  6.41s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979114\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.994709\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994709\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[844]\tvalid's auc: 0.994709\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.9947089947089947 and parameters: {'feature_fraction': 0.5594437011958917, 'num_leaves': 100, 'bagging_fraction': 0.7522817525033746, 'min_sum_hessian_in_leaf': 0.032470472874975016, 'reg_alpha': 0.0030432638409728357, 'reg_lambda': 0.04204263878629447}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.5594437011958917, 'num_leaves': 100, 'bagging_fraction': 0.7522817525033746, 'min_sum_hessian_in_leaf': 0.032470472874975016, 'reg_alpha': 0.0030432638409728357, 'reg_lambda': 0.04204263878629447} scored 0.9947089947089947 in 0:00:07.209412\n",
            "Optimization Progress:  19%|█▉        | 19/101 [02:05<09:06,  6.66s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.977444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.984684\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.990253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[815]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.9941520467836258 and parameters: {'feature_fraction': 0.8529694011819124, 'num_leaves': 153, 'bagging_fraction': 0.7384951733619645, 'min_sum_hessian_in_leaf': 0.011691278283965779, 'reg_alpha': 0.012478084317110552, 'reg_lambda': 0.0015579107174789602}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8529694011819124, 'num_leaves': 153, 'bagging_fraction': 0.7384951733619645, 'min_sum_hessian_in_leaf': 0.011691278283965779, 'reg_alpha': 0.012478084317110552, 'reg_lambda': 0.0015579107174789602} scored 0.9941520467836258 in 0:00:11.050438\n",
            "Optimization Progress:  20%|█▉        | 20/101 [02:16<10:46,  7.99s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.981899\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[269]\tvalid's auc: 0.988026\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.9880256196045669 and parameters: {'feature_fraction': 0.6310289172727599, 'num_leaves': 197, 'bagging_fraction': 0.9501074183915024, 'min_sum_hessian_in_leaf': 0.06921195906203297, 'reg_alpha': 0.6849391813641007, 'reg_lambda': 0.00010079030010438313}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.6310289172727599, 'num_leaves': 197, 'bagging_fraction': 0.9501074183915024, 'min_sum_hessian_in_leaf': 0.06921195906203297, 'reg_alpha': 0.6849391813641007, 'reg_lambda': 0.00010079030010438313} scored 0.9880256196045669 in 0:00:02.703934\n",
            "Optimization Progress:  21%|██        | 21/101 [02:19<08:32,  6.41s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.981342\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[711]\tvalid's auc: 0.993595\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.9935950988582568 and parameters: {'feature_fraction': 0.5546793450602746, 'num_leaves': 106, 'bagging_fraction': 0.7897555907556028, 'min_sum_hessian_in_leaf': 0.03579309041936204, 'reg_alpha': 0.0015590925030718923, 'reg_lambda': 0.03360671537053145}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5546793450602746, 'num_leaves': 106, 'bagging_fraction': 0.7897555907556028, 'min_sum_hessian_in_leaf': 0.03579309041936204, 'reg_alpha': 0.0015590925030718923, 'reg_lambda': 0.03360671537053145} scored 0.9935950988582568 in 0:00:06.460280\n",
            "Optimization Progress:  22%|██▏       | 22/101 [02:25<08:28,  6.43s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.982178\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[804]\tvalid's auc: 0.994431\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.9944305207463102 and parameters: {'feature_fraction': 0.503964761533517, 'num_leaves': 98, 'bagging_fraction': 0.715559341621256, 'min_sum_hessian_in_leaf': 0.011383842450439993, 'reg_alpha': 0.0052277778188993766, 'reg_lambda': 0.11160086626071687}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.503964761533517, 'num_leaves': 98, 'bagging_fraction': 0.715559341621256, 'min_sum_hessian_in_leaf': 0.011383842450439993, 'reg_alpha': 0.0052277778188993766, 'reg_lambda': 0.11160086626071687} scored 0.9944305207463102 in 0:00:06.925805\n",
            "Optimization Progress:  23%|██▎       | 23/101 [02:32<08:33,  6.59s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.980228\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.98719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[886]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.9941520467836258 and parameters: {'feature_fraction': 0.5637184884385837, 'num_leaves': 138, 'bagging_fraction': 0.7729955700160261, 'min_sum_hessian_in_leaf': 0.1636933392768108, 'reg_alpha': 0.0002446064034382138, 'reg_lambda': 0.0035726712750348624}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.5637184884385837, 'num_leaves': 138, 'bagging_fraction': 0.7729955700160261, 'min_sum_hessian_in_leaf': 0.1636933392768108, 'reg_alpha': 0.0002446064034382138, 'reg_lambda': 0.0035726712750348624} scored 0.9941520467836258 in 0:00:05.516104\n",
            "Optimization Progress:  24%|██▍       | 24/101 [02:38<08:03,  6.28s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.975216\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.98357\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[773]\tvalid's auc: 0.993038\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.9930381509328877 and parameters: {'feature_fraction': 0.5436126902003238, 'num_leaves': 133, 'bagging_fraction': 0.6531057793958777, 'min_sum_hessian_in_leaf': 0.04233258849327743, 'reg_alpha': 0.2728040394995844, 'reg_lambda': 0.04273477359273406}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.5436126902003238, 'num_leaves': 133, 'bagging_fraction': 0.6531057793958777, 'min_sum_hessian_in_leaf': 0.04233258849327743, 'reg_alpha': 0.2728040394995844, 'reg_lambda': 0.04273477359273406} scored 0.9930381509328877 in 0:00:06.953699\n",
            "Optimization Progress:  25%|██▍       | 25/101 [02:45<08:13,  6.49s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.97633\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.98357\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.985798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.98719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[908]\tvalid's auc: 0.991089\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.9910888331940964 and parameters: {'feature_fraction': 0.6792651342220943, 'num_leaves': 85, 'bagging_fraction': 0.8516451215422097, 'min_sum_hessian_in_leaf': 0.001643140437040545, 'reg_alpha': 0.014886973839763052, 'reg_lambda': 1.3538798263084824}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6792651342220943, 'num_leaves': 85, 'bagging_fraction': 0.8516451215422097, 'min_sum_hessian_in_leaf': 0.001643140437040545, 'reg_alpha': 0.014886973839763052, 'reg_lambda': 1.3538798263084824} scored 0.9910888331940964 in 0:00:06.422127\n",
            "Optimization Progress:  26%|██▌       | 26/101 [02:51<08:05,  6.48s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.978836\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.98719\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[770]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.9941520467836257 and parameters: {'feature_fraction': 0.6039866331340049, 'num_leaves': 18, 'bagging_fraction': 0.7206767414474735, 'min_sum_hessian_in_leaf': 0.016085962446623497, 'reg_alpha': 0.00024390579935275612, 'reg_lambda': 1.7269547587376765e-06}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.6039866331340049, 'num_leaves': 18, 'bagging_fraction': 0.7206767414474735, 'min_sum_hessian_in_leaf': 0.016085962446623497, 'reg_alpha': 0.00024390579935275612, 'reg_lambda': 1.7269547587376765e-06} scored 0.9941520467836257 in 0:00:09.104900\n",
            "Optimization Progress:  27%|██▋       | 27/101 [03:00<08:58,  7.27s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979671\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986912\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1014]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.5595903838072143, 'num_leaves': 149, 'bagging_fraction': 0.7639736774998268, 'min_sum_hessian_in_leaf': 0.20507447696982062, 'reg_alpha': 0.0006534489584157231, 'reg_lambda': 0.0011627263181236637}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.5595903838072143, 'num_leaves': 149, 'bagging_fraction': 0.7639736774998268, 'min_sum_hessian_in_leaf': 0.20507447696982062, 'reg_alpha': 0.0006534489584157231, 'reg_lambda': 0.0011627263181236637} scored 0.9933166248955723 in 0:00:05.828264\n",
            "Optimization Progress:  28%|██▊       | 28/101 [03:06<08:19,  6.85s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.977444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.985798\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.990253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[942]\tvalid's auc: 0.992481\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.9924812030075187 and parameters: {'feature_fraction': 0.5313164347947685, 'num_leaves': 127, 'bagging_fraction': 0.8308729866222075, 'min_sum_hessian_in_leaf': 0.06662730298170669, 'reg_alpha': 0.03328789770726662, 'reg_lambda': 0.48577021013824917}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5313164347947685, 'num_leaves': 127, 'bagging_fraction': 0.8308729866222075, 'min_sum_hessian_in_leaf': 0.06662730298170669, 'reg_alpha': 0.03328789770726662, 'reg_lambda': 0.48577021013824917} scored 0.9924812030075187 in 0:00:08.670116\n",
            "Optimization Progress:  29%|██▊       | 29/101 [03:15<08:52,  7.40s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.958786\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.966583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.973823\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.978836\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.983292\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.984962\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.985519\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.986076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1400]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1500]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1600]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1700]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1574]\tvalid's auc: 0.98914\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.9891395154553049 and parameters: {'feature_fraction': 0.6229756997163277, 'num_leaves': 255, 'bagging_fraction': 0.906708728779495, 'min_sum_hessian_in_leaf': 0.30173268780226314, 'reg_alpha': 3.714344152073746e-05, 'reg_lambda': 7.722915471851603}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6229756997163277, 'num_leaves': 255, 'bagging_fraction': 0.906708728779495, 'min_sum_hessian_in_leaf': 0.30173268780226314, 'reg_alpha': 3.714344152073746e-05, 'reg_lambda': 7.722915471851603} scored 0.9891395154553049 in 0:00:11.284281\n",
            "Optimization Progress:  30%|██▉       | 30/101 [03:26<10:08,  8.57s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.981342\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986633\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[419]\tvalid's auc: 0.990253\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.9902534113060428 and parameters: {'feature_fraction': 0.5886021599621556, 'num_leaves': 114, 'bagging_fraction': 0.885915490166865, 'min_sum_hessian_in_leaf': 1.5572996169421485, 'reg_alpha': 0.0057908158044508995, 'reg_lambda': 0.00013266592101394018}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5886021599621556, 'num_leaves': 114, 'bagging_fraction': 0.885915490166865, 'min_sum_hessian_in_leaf': 1.5572996169421485, 'reg_alpha': 0.0057908158044508995, 'reg_lambda': 0.00013266592101394018} scored 0.9902534113060428 in 0:00:02.992692\n",
            "Optimization Progress:  31%|███       | 31/101 [03:29<08:03,  6.91s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.978279\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986633\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[594]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.9941520467836257 and parameters: {'feature_fraction': 0.5064585846789635, 'num_leaves': 225, 'bagging_fraction': 0.6422523250922003, 'min_sum_hessian_in_leaf': 0.25652065228839277, 'reg_alpha': 2.273789191302887e-06, 'reg_lambda': 0.01074467794504669}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5064585846789635, 'num_leaves': 225, 'bagging_fraction': 0.6422523250922003, 'min_sum_hessian_in_leaf': 0.25652065228839277, 'reg_alpha': 2.273789191302887e-06, 'reg_lambda': 0.01074467794504669} scored 0.9941520467836257 in 0:00:03.617619\n",
            "Optimization Progress:  32%|███▏      | 32/101 [03:33<06:49,  5.93s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.97076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.982178\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[885]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.9938735728209412 and parameters: {'feature_fraction': 0.5268746134180258, 'num_leaves': 213, 'bagging_fraction': 0.5900833019738507, 'min_sum_hessian_in_leaf': 0.5041922608773242, 'reg_alpha': 1.7936505732593054e-05, 'reg_lambda': 0.0008513910264459914}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.5268746134180258, 'num_leaves': 213, 'bagging_fraction': 0.5900833019738507, 'min_sum_hessian_in_leaf': 0.5041922608773242, 'reg_alpha': 1.7936505732593054e-05, 'reg_lambda': 0.0008513910264459914} scored 0.9938735728209412 in 0:00:07.142839\n",
            "Optimization Progress:  33%|███▎      | 33/101 [03:40<07:08,  6.30s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.97076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.983292\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[680]\tvalid's auc: 0.993038\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.9930381509328878 and parameters: {'feature_fraction': 0.5362109127790042, 'num_leaves': 184, 'bagging_fraction': 0.562296220482492, 'min_sum_hessian_in_leaf': 1.1598630173023612, 'reg_alpha': 5.48092393488785e-07, 'reg_lambda': 0.04814927932883483}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5362109127790042, 'num_leaves': 184, 'bagging_fraction': 0.562296220482492, 'min_sum_hessian_in_leaf': 1.1598630173023612, 'reg_alpha': 5.48092393488785e-07, 'reg_lambda': 0.04814927932883483} scored 0.9930381509328878 in 0:00:02.980841\n",
            "Optimization Progress:  34%|███▎      | 34/101 [03:43<05:55,  5.31s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.982456\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[493]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.9938735728209411 and parameters: {'feature_fraction': 0.5021743408713989, 'num_leaves': 168, 'bagging_fraction': 0.7036081401591736, 'min_sum_hessian_in_leaf': 0.0869512045535172, 'reg_alpha': 0.0003997120822002855, 'reg_lambda': 0.0002721869664502723}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5021743408713989, 'num_leaves': 168, 'bagging_fraction': 0.7036081401591736, 'min_sum_hessian_in_leaf': 0.0869512045535172, 'reg_alpha': 0.0003997120822002855, 'reg_lambda': 0.0002721869664502723} scored 0.9938735728209411 in 0:00:03.625758\n",
            "Optimization Progress:  35%|███▍      | 35/101 [03:47<05:17,  4.82s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.976608\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.983013\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[589]\tvalid's auc: 0.993317\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.9933166248955723 and parameters: {'feature_fraction': 0.6651347626062353, 'num_leaves': 88, 'bagging_fraction': 0.6667560123524132, 'min_sum_hessian_in_leaf': 0.006679635576127872, 'reg_alpha': 1.2543362903833723e-05, 'reg_lambda': 3.431262209291715e-05}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.6651347626062353, 'num_leaves': 88, 'bagging_fraction': 0.6667560123524132, 'min_sum_hessian_in_leaf': 0.006679635576127872, 'reg_alpha': 1.2543362903833723e-05, 'reg_lambda': 3.431262209291715e-05} scored 0.9933166248955723 in 0:00:08.538898\n",
            "Optimization Progress:  36%|███▌      | 36/101 [03:55<06:26,  5.94s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.980228\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[542]\tvalid's auc: 0.99276\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.9927596769702033 and parameters: {'feature_fraction': 0.5699952597245679, 'num_leaves': 77, 'bagging_fraction': 0.8084546969347595, 'min_sum_hessian_in_leaf': 0.00315801000836808, 'reg_alpha': 0.00011074262068914824, 'reg_lambda': 0.0030580264105793636}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.5699952597245679, 'num_leaves': 77, 'bagging_fraction': 0.8084546969347595, 'min_sum_hessian_in_leaf': 0.00315801000836808, 'reg_alpha': 0.00011074262068914824, 'reg_lambda': 0.0030580264105793636} scored 0.9927596769702033 in 0:00:06.516271\n",
            "Optimization Progress:  37%|███▋      | 37/101 [04:02<06:31,  6.12s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.969646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.982735\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991646\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[733]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.9941520467836258 and parameters: {'feature_fraction': 0.5355728244027852, 'num_leaves': 200, 'bagging_fraction': 0.5015166835211706, 'min_sum_hessian_in_leaf': 0.02609239728515521, 'reg_alpha': 1.1544959676962314e-06, 'reg_lambda': 3.959375143012411e-07}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.5355728244027852, 'num_leaves': 200, 'bagging_fraction': 0.5015166835211706, 'min_sum_hessian_in_leaf': 0.02609239728515521, 'reg_alpha': 1.1544959676962314e-06, 'reg_lambda': 3.959375143012411e-07} scored 0.9941520467836258 in 0:00:10.076848\n",
            "Optimization Progress:  38%|███▊      | 38/101 [04:12<07:40,  7.32s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.968254\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.973823\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.983292\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.985241\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.986076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.986912\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.987747\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1200]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1102]\tvalid's auc: 0.98914\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.989139515455305 and parameters: {'feature_fraction': 0.7147702000373799, 'num_leaves': 42, 'bagging_fraction': 0.6148726166362567, 'min_sum_hessian_in_leaf': 0.6940585172517748, 'reg_alpha': 1.2970993460447349, 'reg_lambda': 0.00045276640563333937}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.7147702000373799, 'num_leaves': 42, 'bagging_fraction': 0.6148726166362567, 'min_sum_hessian_in_leaf': 0.6940585172517748, 'reg_alpha': 1.2970993460447349, 'reg_lambda': 0.00045276640563333937} scored 0.989139515455305 in 0:00:04.250000\n",
            "Optimization Progress:  39%|███▊      | 39/101 [04:16<06:37,  6.40s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.966305\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.983849\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.98914\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.990253\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[916]\tvalid's auc: 0.994152\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.9941520467836258 and parameters: {'feature_fraction': 0.9038770256259454, 'num_leaves': 238, 'bagging_fraction': 0.6385723015323361, 'min_sum_hessian_in_leaf': 0.14856573329411374, 'reg_alpha': 0.002941990154026856, 'reg_lambda': 8.823345782913323e-05}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9038770256259454, 'num_leaves': 238, 'bagging_fraction': 0.6385723015323361, 'min_sum_hessian_in_leaf': 0.14856573329411374, 'reg_alpha': 0.002941990154026856, 'reg_lambda': 8.823345782913323e-05} scored 0.9941520467836258 in 0:00:10.945281\n",
            "Optimization Progress:  40%|███▉      | 40/101 [04:27<07:54,  7.77s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.97076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.983013\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.988304\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[884]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.9938735728209412 and parameters: {'feature_fraction': 0.6145752398588344, 'num_leaves': 221, 'bagging_fraction': 0.5800731387746403, 'min_sum_hessian_in_leaf': 0.3943203508652826, 'reg_alpha': 9.292955794733439e-08, 'reg_lambda': 0.07083666230850431}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.6145752398588344, 'num_leaves': 221, 'bagging_fraction': 0.5800731387746403, 'min_sum_hessian_in_leaf': 0.3943203508652826, 'reg_alpha': 9.292955794733439e-08, 'reg_lambda': 0.07083666230850431} scored 0.9938735728209412 in 0:00:07.421283\n",
            "Optimization Progress:  41%|████      | 41/101 [04:35<07:40,  7.68s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.980785\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[473]\tvalid's auc: 0.993595\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.9935950988582567 and parameters: {'feature_fraction': 0.5005834130361284, 'num_leaves': 101, 'bagging_fraction': 0.7039324496586553, 'min_sum_hessian_in_leaf': 0.009172180384494726, 'reg_alpha': 0.0068077805753431935, 'reg_lambda': 0.156475557748798}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.5005834130361284, 'num_leaves': 101, 'bagging_fraction': 0.7039324496586553, 'min_sum_hessian_in_leaf': 0.009172180384494726, 'reg_alpha': 0.0068077805753431935, 'reg_lambda': 0.156475557748798} scored 0.9935950988582567 in 0:00:03.479767\n",
            "Optimization Progress:  42%|████▏     | 42/101 [04:38<06:19,  6.43s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.97271\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.980507\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.984127\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.988583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.990532\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.989975\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[596]\tvalid's auc: 0.990532\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.9905318852687273 and parameters: {'feature_fraction': 0.5240626851221186, 'num_leaves': 100, 'bagging_fraction': 0.7194398660625877, 'min_sum_hessian_in_leaf': 0.03843368959059408, 'reg_alpha': 0.0010584146261584325, 'reg_lambda': 2.1534084003981855}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.5240626851221186, 'num_leaves': 100, 'bagging_fraction': 0.7194398660625877, 'min_sum_hessian_in_leaf': 0.03843368959059408, 'reg_alpha': 0.0010584146261584325, 'reg_lambda': 2.1534084003981855} scored 0.9905318852687273 in 0:00:03.214628\n",
            "Optimization Progress:  43%|████▎     | 43/101 [04:41<05:17,  5.47s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.978558\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.99276\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.992481\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.993595\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[601]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.9938735728209414 and parameters: {'feature_fraction': 0.5729154527279681, 'num_leaves': 72, 'bagging_fraction': 0.7505026631019918, 'min_sum_hessian_in_leaf': 0.003699254866525637, 'reg_alpha': 0.020939467444460052, 'reg_lambda': 0.008875739292370706}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5729154527279681, 'num_leaves': 72, 'bagging_fraction': 0.7505026631019918, 'min_sum_hessian_in_leaf': 0.003699254866525637, 'reg_alpha': 0.020939467444460052, 'reg_lambda': 0.008875739292370706} scored 0.9938735728209414 in 0:00:07.711312\n",
            "Optimization Progress:  44%|████▎     | 44/101 [04:49<05:50,  6.15s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.975216\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.983292\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.986076\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.986355\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.987469\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.989418\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.989696\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.99081\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1100]\tvalid's auc: 0.991089\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[925]\tvalid's auc: 0.991089\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.9910888331940964 and parameters: {'feature_fraction': 0.5231290145835545, 'num_leaves': 116, 'bagging_fraction': 0.6736607256020085, 'min_sum_hessian_in_leaf': 0.017443465161509245, 'reg_alpha': 0.1642480968858465, 'reg_lambda': 0.4324570485734609}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.5231290145835545, 'num_leaves': 116, 'bagging_fraction': 0.6736607256020085, 'min_sum_hessian_in_leaf': 0.017443465161509245, 'reg_alpha': 0.1642480968858465, 'reg_lambda': 0.4324570485734609} scored 0.9910888331940964 in 0:00:04.459174\n",
            "Optimization Progress:  45%|████▍     | 45/101 [04:54<05:16,  5.65s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.979393\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988026\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.992203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.991924\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.994152\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[1000]\tvalid's auc: 0.994431\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[807]\tvalid's auc: 0.994431\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.9944305207463102 and parameters: {'feature_fraction': 0.551266832153455, 'num_leaves': 145, 'bagging_fraction': 0.7194751085097859, 'min_sum_hessian_in_leaf': 0.009669851604594819, 'reg_alpha': 0.0026361815236787597, 'reg_lambda': 0.017352364851872363}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.551266832153455, 'num_leaves': 145, 'bagging_fraction': 0.7194751085097859, 'min_sum_hessian_in_leaf': 0.009669851604594819, 'reg_alpha': 0.0026361815236787597, 'reg_lambda': 0.017352364851872363} scored 0.9944305207463102 in 0:00:05.483371\n",
            "Optimization Progress:  46%|████▌     | 46/101 [04:59<05:08,  5.62s/it, best_trial=10, best_value=0.995]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.982178\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.988861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.991367\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.993038\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.993317\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[369]\tvalid's auc: 0.993874\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.9938735728209414 and parameters: {'feature_fraction': 0.582490282148293, 'num_leaves': 91, 'bagging_fraction': 0.7840540424740476, 'min_sum_hessian_in_leaf': 0.02641649303342018, 'reg_alpha': 0.005986068356711847, 'reg_lambda': 0.13966906496393283}. Best is trial 10 with value: 0.9947089947089947.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.582490282148293, 'num_leaves': 91, 'bagging_fraction': 0.7840540424740476, 'min_sum_hessian_in_leaf': 0.02641649303342018, 'reg_alpha': 0.005986068356711847, 'reg_lambda': 0.13966906496393283} scored 0.9938735728209414 in 0:00:06.198110\n",
            "Optimization Progress:  47%|████▋     | 47/101 [05:05<05:51,  6.51s/it, best_trial=10, best_value=0.995]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:25] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:25] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527}\u001b[0m\n",
            " achieve 0.9947 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.5102569642516215, 'num_leaves': 152, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.024400771927662206, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527}\u001b[0m\n",
            " achieve 0.9947 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 152, 'feature_fraction': 0.5102569642516215, 'bagging_fraction': 0.6843643863605486, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.0031424128733854874, 'reg_lambda': 0.016301353379407527, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.024400771927662206}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:25] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.993874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.995823\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[161]\tvalid's auc: 0.99638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:27] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.946158\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.948052\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.961039\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.960768\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[350]\tvalid's auc: 0.96158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:28] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.989448\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.992695\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.992965\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[272]\tvalid's auc: 0.993777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:30] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.983225\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.98539\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[145]\tvalid's auc: 0.986472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:31] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.968885\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.974567\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.974838\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.975379\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[398]\tvalid's auc: 0.97592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.973421565319605\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.973421565319605\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:33] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6886661\tbest: 0.6886661 (0)\ttotal: 8.62ms\tremaining: 4.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9866332\tbest: 0.9866332 (100)\ttotal: 1.47s\tremaining: 5.79s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9860763\tbest: 0.9877471 (104)\ttotal: 2.82s\tremaining: 4.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9877471456\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 104\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 105 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:36] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6097132\tbest: 0.6097132 (0)\ttotal: 21.7ms\tremaining: 10.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9315476\tbest: 0.9326299 (98)\ttotal: 1.19s\tremaining: 4.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9437229\tbest: 0.9437229 (181)\ttotal: 1.69s\tremaining: 2.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9507576\tbest: 0.9510281 (296)\ttotal: 2.23s\tremaining: 1.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9577922\tbest: 0.9577922 (392)\ttotal: 2.73s\tremaining: 675ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9634740\tbest: 0.9634740 (497)\ttotal: 3.25s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.963474026\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 497\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 498 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:40] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6022727\tbest: 0.6022727 (0)\ttotal: 5.7ms\tremaining: 2.85s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9764610\tbest: 0.9764610 (100)\ttotal: 511ms\tremaining: 2.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9899892\tbest: 0.9902597 (176)\ttotal: 1.04s\tremaining: 1.55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9940476\tbest: 0.9948593 (270)\ttotal: 1.55s\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9948593074\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 270\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 271 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:42] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7610931\tbest: 0.7610931 (0)\ttotal: 5.4ms\tremaining: 2.69s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9894481\tbest: 0.9908009 (90)\ttotal: 513ms\tremaining: 2.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9948593\tbest: 0.9954004 (197)\ttotal: 1.05s\tremaining: 1.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9970238\tbest: 0.9970238 (297)\ttotal: 1.54s\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9970238095\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 297\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 298 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:44] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6778950\tbest: 0.6778950 (0)\ttotal: 5.33ms\tremaining: 2.66s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9442641\tbest: 0.9442641 (96)\ttotal: 497ms\tremaining: 1.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9637446\tbest: 0.9637446 (200)\ttotal: 1.02s\tremaining: 1.51s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9724026\tbest: 0.9724026 (299)\ttotal: 1.51s\tremaining: 999ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9797078\tbest: 0.9805195 (360)\ttotal: 2.04s\tremaining: 503ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9848485\tbest: 0.9862013 (489)\ttotal: 2.56s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9862012987\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 489\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 490 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9747602825455219\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9747602825455219\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:47] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:16:47] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-4f805091-1b54-41bc-8480-0218a402b271\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 4.35ms\tremaining: 2.17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9582289\tbest: 0.9718741 (56)\ttotal: 365ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9718741298\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 56\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 57 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.9718741297688666 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.9718741297688666.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.9718741297688666 in 0:00:00.820083\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<01:24,  1.18it/s, best_trial=0, best_value=0.972]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6396547\tbest: 0.6396547 (0)\ttotal: 10.9ms\tremaining: 5.45s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9365079\tbest: 0.9493177 (66)\ttotal: 533ms\tremaining: 2.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9587859\tbest: 0.9587859 (200)\ttotal: 1.21s\tremaining: 1.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9685324\tbest: 0.9702033 (291)\ttotal: 1.95s\tremaining: 1.29s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.970203286\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 291\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 292 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.9702032859927597 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.9718741297688666.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.9702032859927597 in 0:00:02.808947\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:03<03:19,  2.02s/it, best_trial=0, best_value=0.972]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 4.49ms\tremaining: 2.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9629630\tbest: 0.9629630 (100)\ttotal: 678ms\tremaining: 2.68s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9532164\tbest: 0.9710387 (122)\ttotal: 1.22s\tremaining: 1.81s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9710387079\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 122\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 123 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.9710387078808131 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.9718741297688666.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.9710387078808131 in 0:00:01.514169\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:05<02:55,  1.80s/it, best_trial=0, best_value=0.972]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6396547\tbest: 0.6396547 (0)\ttotal: 2.96ms\tremaining: 1.48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9398496\tbest: 0.9451406 (80)\ttotal: 275ms\tremaining: 1.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9546087\tbest: 0.9546087 (200)\ttotal: 520ms\tremaining: 773ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9624060\tbest: 0.9624060 (300)\ttotal: 768ms\tremaining: 507ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9688109\tbest: 0.9690894 (396)\ttotal: 1.02s\tremaining: 251ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9813422\tbest: 0.9821777 (492)\ttotal: 1.28s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9821776664\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 492\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 493 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.9821776663881927 and parameters: {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6}. Best is trial 3 with value: 0.9821776663881927.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored 0.9821776663881927 in 0:00:01.493693\n",
            "Optimization Progress:   4%|▍         | 4/101 [00:06<02:43,  1.68s/it, best_trial=3, best_value=0.982]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7007797\tbest: 0.7007797 (0)\ttotal: 12.1ms\tremaining: 6.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9743804\tbest: 0.9766082 (90)\ttotal: 791ms\tremaining: 3.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9860763\tbest: 0.9863548 (187)\ttotal: 1.55s\tremaining: 2.31s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9863548\tbest: 0.9902534 (257)\ttotal: 2.33s\tremaining: 1.54s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9905319\tbest: 0.9919243 (355)\ttotal: 3.1s\tremaining: 767ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9935951\tbest: 0.9938736 (487)\ttotal: 3.88s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9938735728\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 487\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 488 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.9938735728209414 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored 0.9938735728209414 in 0:00:04.100880\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:10<04:05,  2.56s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7007797\tbest: 0.7007797 (0)\ttotal: 7.76ms\tremaining: 3.87s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9791145\tbest: 0.9791145 (100)\ttotal: 843ms\tremaining: 3.33s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9880256\tbest: 0.9880256 (200)\ttotal: 1.66s\tremaining: 2.46s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9835700\tbest: 0.9885826 (235)\ttotal: 2.46s\tremaining: 1.63s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9885825675\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 235\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 236 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.9885825675299359 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.9885825675299359 in 0:00:03.459809\n",
            "Optimization Progress:   6%|▌         | 6/101 [00:14<04:32,  2.87s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8160679\tbest: 0.8160679 (0)\ttotal: 7.8ms\tremaining: 3.89s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9643553\tbest: 0.9651908 (62)\ttotal: 995ms\tremaining: 3.93s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9813422\tbest: 0.9821777 (176)\ttotal: 2.88s\tremaining: 4.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9849624\tbest: 0.9855194 (284)\ttotal: 4.72s\tremaining: 3.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9863548\tbest: 0.9871902 (370)\ttotal: 5.59s\tremaining: 1.38s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9871902\tbest: 0.9874687 (435)\ttotal: 6.4s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9874686717\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 435\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 436 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.987468671679198 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored 0.987468671679198 in 0:00:06.647447\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:20<06:26,  4.11s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15ms\tremaining: 7.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9860763\tbest: 0.9916458 (78)\ttotal: 1.35s\tremaining: 5.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9916457811\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 78\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 79 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.9916457811194652 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored 0.9916457811194652 in 0:00:02.540392\n",
            "Optimization Progress:   8%|▊         | 8/101 [00:23<05:36,  3.62s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 3.42ms\tremaining: 1.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9484823\tbest: 0.9487608 (94)\ttotal: 258ms\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9637984\tbest: 0.9637984 (200)\ttotal: 505ms\tremaining: 751ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9679755\tbest: 0.9693679 (296)\ttotal: 780ms\tremaining: 516ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9727096\tbest: 0.9760512 (372)\ttotal: 1.03s\tremaining: 253ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9807853\tbest: 0.9807853 (498)\ttotal: 1.32s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9807852966\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 498\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 499 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.9807852965747703 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored 0.9807852965747703 in 0:00:01.512182\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:25<04:32,  2.96s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7021721\tbest: 0.7021721 (0)\ttotal: 10.7ms\tremaining: 5.33s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9841270\tbest: 0.9841270 (100)\ttotal: 778ms\tremaining: 3.07s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9855194\tbest: 0.9919243 (161)\ttotal: 2.14s\tremaining: 3.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9919242551\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 161\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 162 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.9919242550821499 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored 0.9919242550821499 in 0:00:02.834253\n",
            "Optimization Progress:  10%|▉         | 10/101 [00:27<04:26,  2.93s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6886661\tbest: 0.6886661 (0)\ttotal: 6.79ms\tremaining: 3.38s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9785575\tbest: 0.9810638 (58)\ttotal: 510ms\tremaining: 2.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9805068\tbest: 0.9877471 (135)\ttotal: 1.03s\tremaining: 1.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9877471456\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 135\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 136 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.9877471456418825 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 13}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 1.169299795821202e-08, 'min_data_in_leaf': 13} scored 0.9877471456418825 in 0:00:01.409212\n",
            "Optimization Progress:  11%|█         | 11/101 [00:29<03:42,  2.47s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6993874\tbest: 0.6993874 (0)\ttotal: 22.4ms\tremaining: 11.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9743804\tbest: 0.9785575 (90)\ttotal: 2.02s\tremaining: 7.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9785575049\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 90\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 91 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.9785575048732944 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.623917803986404e-05, 'min_data_in_leaf': 11}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 2.623917803986404e-05, 'min_data_in_leaf': 11} scored 0.9785575048732944 in 0:00:04.160455\n",
            "Optimization Progress:  12%|█▏        | 12/101 [00:33<04:26,  2.99s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 15.2ms\tremaining: 7.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9816207\tbest: 0.9863548 (40)\ttotal: 1.27s\tremaining: 5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9888610\tbest: 0.9888610 (199)\ttotal: 2.53s\tremaining: 3.77s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9860763\tbest: 0.9902534 (240)\ttotal: 3.79s\tremaining: 2.51s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9902534113\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 240\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 241 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.9902534113060428 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.3639426888455197e-06, 'min_data_in_leaf': 16}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 3.3639426888455197e-06, 'min_data_in_leaf': 16} scored 0.9902534113060428 in 0:00:04.527618\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:38<05:04,  3.46s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6886661\tbest: 0.6886661 (0)\ttotal: 5.4ms\tremaining: 2.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9852409\tbest: 0.9860763 (95)\ttotal: 532ms\tremaining: 2.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9869117\tbest: 0.9871902 (193)\ttotal: 1.11s\tremaining: 1.65s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9905319\tbest: 0.9908104 (271)\ttotal: 1.63s\tremaining: 1.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9905319\tbest: 0.9919243 (330)\ttotal: 2.17s\tremaining: 537ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9919242551\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 330\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 331 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.9919242550821498 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.07029033705325562, 'min_data_in_leaf': 9}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 0.07029033705325562, 'min_data_in_leaf': 9} scored 0.9919242550821498 in 0:00:02.585693\n",
            "Optimization Progress:  14%|█▍        | 14/101 [00:40<04:38,  3.20s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6993874\tbest: 0.6993874 (0)\ttotal: 8.68ms\tremaining: 4.33s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9835700\tbest: 0.9835700 (96)\ttotal: 809ms\tremaining: 3.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9838485\tbest: 0.9874687 (133)\ttotal: 1.6s\tremaining: 2.38s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9899749\tbest: 0.9905319 (253)\ttotal: 2.36s\tremaining: 1.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9905319\tbest: 0.9910888 (339)\ttotal: 3.75s\tremaining: 925ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9910888332\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 339\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 340 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.9910888331940964 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 5.009652270703273e-07, 'min_data_in_leaf': 1}. Best is trial 4 with value: 0.9938735728209414.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 5.009652270703273e-07, 'min_data_in_leaf': 1} scored 0.9910888331940964 in 0:00:04.571679\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:45<05:11,  3.62s/it, best_trial=4, best_value=0.994]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 18.6ms\tremaining: 9.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9935951\tbest: 0.9952659 (50)\ttotal: 2.57s\tremaining: 10.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9952659426\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 50\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 51 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.9952659426343637 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001653282123997984, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0001653282123997984, 'min_data_in_leaf': 7} scored 0.9952659426343637 in 0:00:03.483815\n",
            "Optimization Progress:  16%|█▌        | 16/101 [00:48<05:04,  3.59s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12.5ms\tremaining: 6.23s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9835700\tbest: 0.9860763 (38)\ttotal: 1.28s\tremaining: 5.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9913673\tbest: 0.9913673 (200)\ttotal: 2.54s\tremaining: 3.78s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9927597\tbest: 0.9927597 (286)\ttotal: 3.81s\tremaining: 2.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9941520\tbest: 0.9944305 (385)\ttotal: 5.08s\tremaining: 1.25s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9944305207\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 385\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 386 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.9944305207463102 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.746304243335191e-05, 'min_data_in_leaf': 11}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.746304243335191e-05, 'min_data_in_leaf': 11} scored 0.9944305207463102 in 0:00:06.444772\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:55<06:13,  4.45s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 13ms\tremaining: 6.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9899749\tbest: 0.9949875 (54)\ttotal: 1.25s\tremaining: 4.93s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0014772748467521e-07, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.0014772748467521e-07, 'min_data_in_leaf': 12} scored 0.9949874686716791 in 0:00:02.123088\n",
            "Optimization Progress:  18%|█▊        | 18/101 [00:57<05:11,  3.76s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 24.9ms\tremaining: 12.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9910888\tbest: 0.9949875 (54)\ttotal: 2.88s\tremaining: 11.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1252454598457274e-07, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.1252454598457274e-07, 'min_data_in_leaf': 7} scored 0.9949874686716791 in 0:00:04.871415\n",
            "Optimization Progress:  19%|█▉        | 19/101 [01:02<05:36,  4.10s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6304651\tbest: 0.6304651 (0)\ttotal: 5ms\tremaining: 2.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9699248\tbest: 0.9724311 (35)\ttotal: 390ms\tremaining: 1.54s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9741019\tbest: 0.9807853 (178)\ttotal: 739ms\tremaining: 1.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9807852966\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 178\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 179 iterations.\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.9807852965747702 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.670179359935494e-08, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 1.670179359935494e-08, 'min_data_in_leaf': 18} scored 0.9807852965747702 in 0:00:01.227255\n",
            "Optimization Progress:  20%|█▉        | 20/101 [01:03<04:22,  3.24s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 15.2ms\tremaining: 7.58s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9880256\tbest: 0.9894180 (82)\ttotal: 1.27s\tremaining: 5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9894179894\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 82\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 83 iterations.\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.9894179894179894 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.09877202927080148, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 0.09877202927080148, 'min_data_in_leaf': 13} scored 0.9894179894179894 in 0:00:02.535500\n",
            "Optimization Progress:  21%|██        | 21/101 [01:06<04:02,  3.04s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12.7ms\tremaining: 6.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9930382\tbest: 0.9949875 (54)\ttotal: 1.26s\tremaining: 4.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.386642013645327e-08, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.386642013645327e-08, 'min_data_in_leaf': 7} scored 0.9949874686716791 in 0:00:02.169784\n",
            "Optimization Progress:  22%|██▏       | 22/101 [01:08<03:39,  2.78s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12.2ms\tremaining: 6.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9908104\tbest: 0.9949875 (54)\ttotal: 1.29s\tremaining: 5.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9360196330961578e-07, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9360196330961578e-07, 'min_data_in_leaf': 8} scored 0.9949874686716791 in 0:00:02.185105\n",
            "Optimization Progress:  23%|██▎       | 23/101 [01:10<03:23,  2.61s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12.4ms\tremaining: 6.17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9807853\tbest: 0.9863548 (40)\ttotal: 1.26s\tremaining: 4.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9863547758\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 40\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 41 iterations.\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.9863547758284601 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.811580364035183e-06, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.811580364035183e-06, 'min_data_in_leaf': 13} scored 0.9863547758284601 in 0:00:02.440446\n",
            "Optimization Progress:  24%|██▍       | 24/101 [01:12<03:17,  2.57s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 34ms\tremaining: 17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9910888\tbest: 0.9949875 (54)\ttotal: 2.8s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 8.165310982087608e-08, 'min_data_in_leaf': 5}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 8.165310982087608e-08, 'min_data_in_leaf': 5} scored 0.9949874686716791 in 0:00:03.973348\n",
            "Optimization Progress:  25%|██▍       | 25/101 [01:16<03:47,  3.00s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6886661\tbest: 0.6886661 (0)\ttotal: 6.62ms\tremaining: 3.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9791145\tbest: 0.9810638 (58)\ttotal: 545ms\tremaining: 2.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9774436\tbest: 0.9894180 (119)\ttotal: 1.07s\tremaining: 1.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9894179894\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 119\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 120 iterations.\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.9894179894179894 and parameters: {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3374731740942595e-06, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Min', 'l2_leaf_reg': 2.3374731740942595e-06, 'min_data_in_leaf': 8} scored 0.9894179894179894 in 0:00:01.378373\n",
            "Optimization Progress:  26%|██▌       | 26/101 [01:18<03:08,  2.52s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 9.53ms\tremaining: 4.76s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9855194\tbest: 0.9855194 (100)\ttotal: 781ms\tremaining: 3.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9902534\tbest: 0.9902534 (200)\ttotal: 1.62s\tremaining: 2.41s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9924812\tbest: 0.9924812 (299)\ttotal: 2.44s\tremaining: 1.61s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.992481203\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 299\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 300 iterations.\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.9924812030075189 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00033655836338300726, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00033655836338300726, 'min_data_in_leaf': 12} scored 0.9924812030075189 in 0:00:03.485359\n",
            "Optimization Progress:  27%|██▋       | 27/101 [01:21<03:28,  2.81s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 17.7ms\tremaining: 8.84s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9908104\tbest: 0.9949875 (54)\ttotal: 1.3s\tremaining: 5.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.437700652139856e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 4.437700652139856e-08, 'min_data_in_leaf': 16} scored 0.9949874686716791 in 0:00:02.196342\n",
            "Optimization Progress:  28%|██▊       | 28/101 [01:24<03:12,  2.63s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6304651\tbest: 0.6304651 (0)\ttotal: 4.72ms\tremaining: 2.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9660262\tbest: 0.9718741 (35)\ttotal: 364ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9702033\tbest: 0.9721526 (126)\ttotal: 756ms\tremaining: 1.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9632414\tbest: 0.9727096 (203)\ttotal: 1.16s\tremaining: 766ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9727095517\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 203\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 204 iterations.\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.9727095516569202 and parameters: {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.0778579286261916e-07, 'min_data_in_leaf': 3}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 4.0778579286261916e-07, 'min_data_in_leaf': 3} scored 0.9727095516569202 in 0:00:01.424779\n",
            "Optimization Progress:  29%|██▊       | 29/101 [01:25<02:43,  2.28s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 9.08ms\tremaining: 4.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9727096\tbest: 0.9727096 (100)\ttotal: 901ms\tremaining: 3.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9777221\tbest: 0.9785575 (199)\ttotal: 2.85s\tremaining: 4.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9793929\tbest: 0.9818992 (246)\ttotal: 4.75s\tremaining: 3.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9830131\tbest: 0.9844055 (386)\ttotal: 5.66s\tremaining: 1.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9841270\tbest: 0.9846839 (428)\ttotal: 6.42s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9846839321\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 428\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 429 iterations.\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.9846839320523532 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 6.5176436757792316e-06, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 6.5176436757792316e-06, 'min_data_in_leaf': 7} scored 0.9846839320523532 in 0:00:06.684038\n",
            "Optimization Progress:  30%|██▉       | 30/101 [01:32<04:16,  3.61s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 16.2ms\tremaining: 8.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9888610\tbest: 0.9896965 (97)\ttotal: 1.25s\tremaining: 4.92s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9916458\tbest: 0.9930382 (191)\ttotal: 2.47s\tremaining: 3.67s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9930381509\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 191\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 192 iterations.\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.9930381509328878 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.265259184516192e-05, 'min_data_in_leaf': 10}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.265259184516192e-05, 'min_data_in_leaf': 10} scored 0.9930381509328878 in 0:00:03.826859\n",
            "Optimization Progress:  31%|███       | 31/101 [01:36<04:17,  3.68s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12.4ms\tremaining: 6.21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9916458\tbest: 0.9949875 (54)\ttotal: 1.28s\tremaining: 5.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 8.089339609894541e-08, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 8.089339609894541e-08, 'min_data_in_leaf': 7} scored 0.9949874686716791 in 0:00:02.132297\n",
            "Optimization Progress:  32%|███▏      | 32/101 [01:38<03:42,  3.22s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 12ms\tremaining: 5.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9894180\tbest: 0.9949875 (54)\ttotal: 1.27s\tremaining: 5.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.387905599466433e-07, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 1.387905599466433e-07, 'min_data_in_leaf': 8} scored 0.9949874686716791 in 0:00:02.848446\n",
            "Optimization Progress:  33%|███▎      | 33/101 [01:41<03:31,  3.12s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 34.3ms\tremaining: 17.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9910888\tbest: 0.9949875 (54)\ttotal: 2.75s\tremaining: 10.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.8201768945617407e-08, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 2.8201768945617407e-08, 'min_data_in_leaf': 6} scored 0.9949874686716791 in 0:00:04.210878\n",
            "Optimization Progress:  34%|███▎      | 34/101 [01:45<03:51,  3.45s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7204121\tbest: 0.7204121 (0)\ttotal: 16.5ms\tremaining: 8.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9930382\tbest: 0.9949875 (54)\ttotal: 1.25s\tremaining: 4.95s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9949874687\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.9949874686716791 and parameters: {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.678770145369204e-07, 'min_data_in_leaf': 3}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Min', 'l2_leaf_reg': 7.678770145369204e-07, 'min_data_in_leaf': 3} scored 0.9949874686716791 in 0:00:02.193486\n",
            "Optimization Progress:  35%|███▍      | 35/101 [01:47<03:23,  3.08s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6993874\tbest: 0.6993874 (0)\ttotal: 8.62ms\tremaining: 4.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9777221\tbest: 0.9788360 (84)\ttotal: 809ms\tremaining: 3.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9791145\tbest: 0.9821777 (191)\ttotal: 1.59s\tremaining: 2.36s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9821776664\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 191\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 192 iterations.\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.9821776663881927 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9616796330501343e-07, 'min_data_in_leaf': 5}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9616796330501343e-07, 'min_data_in_leaf': 5} scored 0.9821776663881927 in 0:00:02.484777\n",
            "Optimization Progress:  36%|███▌      | 36/101 [01:50<03:09,  2.91s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6993874\tbest: 0.6993874 (0)\ttotal: 8.37ms\tremaining: 4.18s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9732665\tbest: 0.9732665 (100)\ttotal: 782ms\tremaining: 3.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9774436\tbest: 0.9791145 (195)\ttotal: 1.57s\tremaining: 2.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9860763\tbest: 0.9863548 (279)\ttotal: 2.36s\tremaining: 1.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9877471\tbest: 0.9883041 (327)\ttotal: 3.17s\tremaining: 783ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9910888\tbest: 0.9913673 (485)\ttotal: 3.93s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9913673072\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 485\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 486 iterations.\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.9913673071567809 and parameters: {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 8.31819570043442e-06, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9952659426343637.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 8.31819570043442e-06, 'min_data_in_leaf': 14} scored 0.9913673071567809 in 0:00:04.177820\n",
            "Optimization Progress:  37%|███▋      | 37/101 [01:54<03:30,  3.30s/it, best_trial=15, best_value=0.995]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 13.1ms\tremaining: 6.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9916458\tbest: 0.9961014 (25)\ttotal: 2.14s\tremaining: 8.46s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0988726118602128e-06, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0988726118602128e-06, 'min_data_in_leaf': 9} scored 0.9961013645224172 in 0:00:03.086060\n",
            "Optimization Progress:  38%|███▊      | 38/101 [01:57<03:24,  3.25s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 13.8ms\tremaining: 6.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9768867\tbest: 0.9844055 (76)\ttotal: 1.78s\tremaining: 7.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9849624\tbest: 0.9885826 (170)\ttotal: 2.58s\tremaining: 3.84s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9905319\tbest: 0.9905319 (299)\ttotal: 3.36s\tremaining: 2.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9894180\tbest: 0.9908104 (331)\ttotal: 4.14s\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9908103592\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 331\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 332 iterations.\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.9908103592314119 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00015446158777906275, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.00015446158777906275, 'min_data_in_leaf': 9} scored 0.9908103592314119 in 0:00:04.721996\n",
            "Optimization Progress:  39%|███▊      | 39/101 [02:02<03:49,  3.70s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15.4ms\tremaining: 7.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9902534\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.909401126040854e-06, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.909401126040854e-06, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.782864\n",
            "Optimization Progress:  40%|███▉      | 40/101 [02:03<03:10,  3.13s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 7.42ms\tremaining: 3.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9668616\tbest: 0.9668616 (100)\ttotal: 756ms\tremaining: 2.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9818992\tbest: 0.9821777 (199)\ttotal: 1.56s\tremaining: 2.33s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9816207\tbest: 0.9846839 (227)\ttotal: 2.36s\tremaining: 1.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9846839321\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 227\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 228 iterations.\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.984683932052353 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.368288318508481e-06, 'min_data_in_leaf': 15}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.368288318508481e-06, 'min_data_in_leaf': 15} scored 0.984683932052353 in 0:00:02.782005\n",
            "Optimization Progress:  41%|████      | 41/101 [02:06<03:01,  3.03s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 13.1ms\tremaining: 6.55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.8385280951715735e-07, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.8385280951715735e-07, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.807798\n",
            "Optimization Progress:  42%|████▏     | 42/101 [02:08<02:37,  2.67s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.5ms\tremaining: 8.26s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9930382\tbest: 0.9961014 (25)\ttotal: 1.97s\tremaining: 7.77s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 7.019310393197251e-06, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 7.019310393197251e-06, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:02.830038\n",
            "Optimization Progress:  43%|████▎     | 43/101 [02:11<02:38,  2.73s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 39.2ms\tremaining: 19.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9910888\tbest: 0.9958229 (25)\ttotal: 2.31s\tremaining: 9.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9958228906\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.9958228905597327 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0185377973662035e-05, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0185377973662035e-05, 'min_data_in_leaf': 11} scored 0.9958228905597327 in 0:00:02.907129\n",
            "Optimization Progress:  44%|████▎     | 44/101 [02:14<02:38,  2.79s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.4ms\tremaining: 8.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9938736\tbest: 0.9958229 (25)\ttotal: 1.27s\tremaining: 5.01s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9902534\tbest: 0.9961014 (111)\ttotal: 2.52s\tremaining: 3.75s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 112 iterations.\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.996101364522417 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4504660965540574e-05, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4504660965540574e-05, 'min_data_in_leaf': 10} scored 0.996101364522417 in 0:00:02.902777\n",
            "Optimization Progress:  45%|████▍     | 45/101 [02:17<02:38,  2.83s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.1ms\tremaining: 6.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9869117\tbest: 0.9958229 (25)\ttotal: 1.28s\tremaining: 5.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9958228906\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.9958228905597327 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.9708266906149754e-05, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.9708266906149754e-05, 'min_data_in_leaf': 10} scored 0.9958228905597327 in 0:00:01.807501\n",
            "Optimization Progress:  46%|████▌     | 46/101 [02:19<02:19,  2.53s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 3.18ms\tremaining: 1.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9437483\tbest: 0.9437483 (87)\ttotal: 257ms\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9303815\tbest: 0.9448622 (101)\ttotal: 535ms\tremaining: 796ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9448621554\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 101\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 102 iterations.\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.9448621553884713 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2085044579545874e-06, 'min_data_in_leaf': 14}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2085044579545874e-06, 'min_data_in_leaf': 14} scored 0.9448621553884713 in 0:00:00.759509\n",
            "Optimization Progress:  47%|████▋     | 47/101 [02:19<01:48,  2.01s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7066277\tbest: 0.7066277 (0)\ttotal: 7ms\tremaining: 3.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9624060\tbest: 0.9651908 (37)\ttotal: 541ms\tremaining: 2.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9824561\tbest: 0.9844055 (151)\ttotal: 1.06s\tremaining: 1.58s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9877471\tbest: 0.9883041 (298)\ttotal: 1.63s\tremaining: 1.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9880256\tbest: 0.9888610 (347)\ttotal: 2.14s\tremaining: 528ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9916458\tbest: 0.9919243 (484)\ttotal: 2.68s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9919242551\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 484\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 485 iterations.\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.9919242550821499 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.908944656369653e-05, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.908944656369653e-05, 'min_data_in_leaf': 12} scored 0.9919242550821499 in 0:00:03.441167\n",
            "Optimization Progress:  48%|████▊     | 48/101 [02:23<02:09,  2.44s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 10ms\tremaining: 4.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9702033\tbest: 0.9702033 (100)\ttotal: 1.94s\tremaining: 7.66s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9844055\tbest: 0.9866332 (183)\ttotal: 3.92s\tremaining: 5.83s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9866332498\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 183\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 184 iterations.\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.9866332497911445 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 5.364707958107654e-06, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 5.364707958107654e-06, 'min_data_in_leaf': 9} scored 0.9866332497911445 in 0:00:05.025904\n",
            "Optimization Progress:  49%|████▊     | 49/101 [02:28<02:47,  3.23s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15.1ms\tremaining: 7.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.2241608226458945e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.2241608226458945e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:01.779354\n",
            "Optimization Progress:  50%|████▉     | 50/101 [02:30<02:22,  2.80s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.5ms\tremaining: 8.73s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9916458\tbest: 0.9961014 (25)\ttotal: 1.28s\tremaining: 5.07s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.861093987903633e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.861093987903633e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.815369\n",
            "Optimization Progress:  50%|█████     | 51/101 [02:32<02:05,  2.51s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.3ms\tremaining: 8.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.0022258865370867e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.0022258865370867e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.797438\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [02:33<01:52,  2.31s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.4ms\tremaining: 8.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9916458\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.98s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8540538334868344e-06, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8540538334868344e-06, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.805565\n",
            "Optimization Progress:  52%|█████▏    | 53/101 [02:35<01:43,  2.16s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.5ms\tremaining: 8.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.1441874319665614e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.1441874319665614e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:01.804897\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [02:37<01:37,  2.06s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 23.1ms\tremaining: 11.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9896965\tbest: 0.9961014 (25)\ttotal: 2.81s\tremaining: 11.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0097514604117552e-06, 'min_data_in_leaf': 14}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0097514604117552e-06, 'min_data_in_leaf': 14} scored 0.9961013645224172 in 0:00:03.765459\n",
            "Optimization Progress:  54%|█████▍    | 55/101 [02:41<01:58,  2.58s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 27.8ms\tremaining: 13.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9688109\tbest: 0.9688109 (100)\ttotal: 1s\tremaining: 3.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9813422\tbest: 0.9821777 (191)\ttotal: 1.78s\tremaining: 2.65s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9807853\tbest: 0.9830131 (229)\ttotal: 2.6s\tremaining: 1.72s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9869117\tbest: 0.9883041 (384)\ttotal: 3.37s\tremaining: 831ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9874687\tbest: 0.9894180 (416)\ttotal: 4.17s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9894179894\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 416\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 417 iterations.\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.9894179894179894 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.7668075134881516e-06, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.7668075134881516e-06, 'min_data_in_leaf': 11} scored 0.9894179894179894 in 0:00:04.514057\n",
            "Optimization Progress:  55%|█████▌    | 56/101 [02:45<02:22,  3.17s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15ms\tremaining: 7.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.426960579764622e-07, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.426960579764622e-07, 'min_data_in_leaf': 13} scored 0.9961013645224172 in 0:00:01.850221\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [02:47<02:02,  2.78s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.1ms\tremaining: 8.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.087767350306725e-08, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.087767350306725e-08, 'min_data_in_leaf': 9} scored 0.9961013645224172 in 0:00:01.842455\n",
            "Optimization Progress:  57%|█████▋    | 58/101 [02:49<01:47,  2.51s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8077137\tbest: 0.8077137 (0)\ttotal: 24.8ms\tremaining: 12.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9743804\tbest: 0.9754943 (99)\ttotal: 816ms\tremaining: 3.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9813422\tbest: 0.9818992 (192)\ttotal: 1.61s\tremaining: 2.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9871902\tbest: 0.9871902 (296)\ttotal: 2.59s\tremaining: 1.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9899749\tbest: 0.9899749 (399)\ttotal: 4.53s\tremaining: 1.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:499:\ttest: 0.9910888\tbest: 0.9910888 (495)\ttotal: 6.48s\tremaining: 0us\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9910888332\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 495\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 496 iterations.\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.9910888331940964 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 9.650554673574426, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 9.650554673574426, 'min_data_in_leaf': 12} scored 0.9910888331940964 in 0:00:06.715281\n",
            "Optimization Progress:  58%|█████▊    | 59/101 [02:56<02:38,  3.78s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15ms\tremaining: 7.48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9846839\tbest: 0.9877471 (25)\ttotal: 1.29s\tremaining: 5.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9922027\tbest: 0.9944305 (179)\ttotal: 2.58s\tremaining: 3.84s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9944305207\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 179\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 180 iterations.\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.9944305207463102 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.004707890709816666, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.004707890709816666, 'min_data_in_leaf': 11} scored 0.9944305207463102 in 0:00:03.870581\n",
            "Optimization Progress:  59%|█████▉    | 60/101 [03:00<02:36,  3.81s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 13.2ms\tremaining: 6.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9863548\tbest: 0.9958229 (25)\ttotal: 1.27s\tremaining: 5.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9958228906\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.9958228905597327 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.146113349524965e-05, 'min_data_in_leaf': 16}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.146113349524965e-05, 'min_data_in_leaf': 16} scored 0.9958228905597327 in 0:00:01.803049\n",
            "Optimization Progress:  60%|██████    | 61/101 [03:02<02:08,  3.22s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.7ms\tremaining: 6.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.32s\tremaining: 5.23s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.649131350202561e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.649131350202561e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:02.448849\n",
            "Optimization Progress:  61%|██████▏   | 62/101 [03:04<01:56,  3.00s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.7ms\tremaining: 8.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.28s\tremaining: 5.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.3413666606846785e-07, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.3413666606846785e-07, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.946374\n",
            "Optimization Progress:  62%|██████▏   | 63/101 [03:06<01:42,  2.69s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 36.7ms\tremaining: 18.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9924812\tbest: 0.9961014 (25)\ttotal: 2.91s\tremaining: 11.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.145326970254036e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.145326970254036e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:03.934359\n",
            "Optimization Progress:  63%|██████▎   | 64/101 [03:10<01:53,  3.08s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 18.7ms\tremaining: 9.36s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9888610\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1766525784296308e-08, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1766525784296308e-08, 'min_data_in_leaf': 13} scored 0.9961013645224172 in 0:00:01.861329\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [03:12<01:37,  2.72s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.5ms\tremaining: 8.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9849624\tbest: 0.9961014 (25)\ttotal: 1.33s\tremaining: 5.27s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.474028175208655e-06, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.474028175208655e-06, 'min_data_in_leaf': 9} scored 0.9961013645224172 in 0:00:01.880603\n",
            "Optimization Progress:  65%|██████▌   | 66/101 [03:14<01:26,  2.48s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.5ms\tremaining: 8.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9922027\tbest: 0.9961014 (25)\ttotal: 1.28s\tremaining: 5.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3895896324651019e-06, 'min_data_in_leaf': 8}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.3895896324651019e-06, 'min_data_in_leaf': 8} scored 0.9961013645224172 in 0:00:01.860264\n",
            "Optimization Progress:  66%|██████▋   | 67/101 [03:16<01:18,  2.30s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 18.3ms\tremaining: 9.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9896965\tbest: 0.9961014 (25)\ttotal: 1.31s\tremaining: 5.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.9840361194288136e-08, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.9840361194288136e-08, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.871373\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [03:18<01:11,  2.18s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7066277\tbest: 0.7066277 (0)\ttotal: 7.34ms\tremaining: 3.66s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9732665\tbest: 0.9760512 (72)\ttotal: 541ms\tremaining: 2.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9782790\tbest: 0.9810638 (163)\ttotal: 1.09s\tremaining: 1.61s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9824561\tbest: 0.9838485 (283)\ttotal: 1.66s\tremaining: 1.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9832916\tbest: 0.9841270 (309)\ttotal: 2.23s\tremaining: 549ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9841269841\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 309\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 310 iterations.\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.9841269841269841 and parameters: {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.97879082565359e-06, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 3.97879082565359e-06, 'min_data_in_leaf': 13} scored 0.9841269841269841 in 0:00:02.542228\n",
            "Optimization Progress:  68%|██████▊   | 69/101 [03:20<01:13,  2.30s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 39.9ms\tremaining: 19.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 2.86s\tremaining: 11.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4718870679934875e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.4718870679934875e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:03.799988\n",
            "Optimization Progress:  69%|██████▉   | 70/101 [03:24<01:25,  2.76s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 32.7ms\tremaining: 16.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9919243\tbest: 0.9961014 (25)\ttotal: 1.47s\tremaining: 5.79s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.987930723278954e-07, 'min_data_in_leaf': 8}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.987930723278954e-07, 'min_data_in_leaf': 8} scored 0.9961013645224172 in 0:00:02.118053\n",
            "Optimization Progress:  70%|███████   | 71/101 [03:26<01:17,  2.58s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 13.4ms\tremaining: 6.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.26s\tremaining: 4.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1608063321504306e-06, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1608063321504306e-06, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.785280\n",
            "Optimization Progress:  71%|███████▏  | 72/101 [03:28<01:08,  2.35s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.7ms\tremaining: 8.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9924812\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.160829898935753e-06, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.160829898935753e-06, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.846386\n",
            "Optimization Progress:  72%|███████▏  | 73/101 [03:30<01:01,  2.21s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.9ms\tremaining: 8.93s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9888610\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.640427154541109e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.640427154541109e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.849834\n",
            "Optimization Progress:  73%|███████▎  | 74/101 [03:32<00:56,  2.11s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 4.03ms\tremaining: 2.01s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9604567\tbest: 0.9768867 (51)\ttotal: 365ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9768866611\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 51\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 52 iterations.\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.9768866610971874 and parameters: {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.91288733936798e-08, 'min_data_in_leaf': 14}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 5.91288733936798e-08, 'min_data_in_leaf': 14} scored 0.9768866610971874 in 0:00:00.807019\n",
            "Optimization Progress:  74%|███████▍  | 75/101 [03:33<00:44,  1.73s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.5ms\tremaining: 8.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9855194\tbest: 0.9961014 (25)\ttotal: 1.28s\tremaining: 5.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.243510102742189e-06, 'min_data_in_leaf': 15}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.243510102742189e-06, 'min_data_in_leaf': 15} scored 0.9961013645224172 in 0:00:01.824498\n",
            "Optimization Progress:  75%|███████▌  | 76/101 [03:34<00:44,  1.77s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 36.8ms\tremaining: 18.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9938736\tbest: 0.9961014 (25)\ttotal: 2.96s\tremaining: 11.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 7.231228127618554e-06, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 7.231228127618554e-06, 'min_data_in_leaf': 9} scored 0.9961013645224172 in 0:00:04.430933\n",
            "Optimization Progress:  76%|███████▌  | 77/101 [03:39<01:01,  2.57s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.8ms\tremaining: 8.37s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9919243\tbest: 0.9961014 (25)\ttotal: 1.29s\tremaining: 5.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.838345913880032e-07, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.838345913880032e-07, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.833075\n",
            "Optimization Progress:  77%|███████▋  | 78/101 [03:41<00:54,  2.36s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 9.94ms\tremaining: 4.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9718741\tbest: 0.9721526 (99)\ttotal: 798ms\tremaining: 3.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9768867\tbest: 0.9768867 (199)\ttotal: 1.62s\tremaining: 2.41s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9813422\tbest: 0.9846839 (282)\ttotal: 2.43s\tremaining: 1.61s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9846839321\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 282\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 283 iterations.\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.9846839320523532 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.156195843106064e-07, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.156195843106064e-07, 'min_data_in_leaf': 13} scored 0.9846839320523532 in 0:00:03.323170\n",
            "Optimization Progress:  78%|███████▊  | 79/101 [03:44<00:58,  2.66s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15.5ms\tremaining: 7.74s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9935951\tbest: 0.9961014 (25)\ttotal: 1.3s\tremaining: 5.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8875903417199782e-06, 'min_data_in_leaf': 20}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.8875903417199782e-06, 'min_data_in_leaf': 20} scored 0.9961013645224172 in 0:00:01.863997\n",
            "Optimization Progress:  79%|███████▉  | 80/101 [03:46<00:51,  2.43s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 12.5ms\tremaining: 6.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9729880\tbest: 0.9802283 (93)\ttotal: 809ms\tremaining: 3.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9782790\tbest: 0.9846839 (160)\ttotal: 1.61s\tremaining: 2.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9846839321\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 160\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 161 iterations.\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.984683932052353 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 4.199102861570569e-05, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 4.199102861570569e-05, 'min_data_in_leaf': 10} scored 0.984683932052353 in 0:00:02.302948\n",
            "Optimization Progress:  80%|████████  | 81/101 [03:48<00:48,  2.40s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 15.2ms\tremaining: 7.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 2.84s\tremaining: 11.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.130846459091829e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.130846459091829e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:03.863950\n",
            "Optimization Progress:  81%|████████  | 82/101 [03:52<00:54,  2.86s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 28.6ms\tremaining: 14.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.63s\tremaining: 6.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 8.504939363393485e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 8.504939363393485e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:02.290319\n",
            "Optimization Progress:  82%|████████▏ | 83/101 [03:55<00:48,  2.70s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.1ms\tremaining: 6.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.33s\tremaining: 5.26s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.793417491908109e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 2.793417491908109e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:01.906047\n",
            "Optimization Progress:  83%|████████▎ | 84/101 [03:57<00:41,  2.47s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.9ms\tremaining: 8.41s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.25s\tremaining: 4.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.632587013722037e-07, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.632587013722037e-07, 'min_data_in_leaf': 12} scored 0.9961013645224172 in 0:00:01.834500\n",
            "Optimization Progress:  84%|████████▍ | 85/101 [03:58<00:36,  2.29s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.6ms\tremaining: 8.77s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9844055\tbest: 0.9958229 (25)\ttotal: 1.3s\tremaining: 5.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9958228906\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.9958228905597327 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.5134184298893115e-05, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.5134184298893115e-05, 'min_data_in_leaf': 9} scored 0.9958228905597327 in 0:00:01.850203\n",
            "Optimization Progress:  85%|████████▌ | 86/101 [04:00<00:32,  2.17s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.1ms\tremaining: 8.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9908104\tbest: 0.9961014 (25)\ttotal: 1.28s\tremaining: 5.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.34285435380058e-06, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 4.34285435380058e-06, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.834962\n",
            "Optimization Progress:  86%|████████▌ | 87/101 [04:02<00:29,  2.08s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.3ms\tremaining: 8.64s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9902534\tbest: 0.9961014 (25)\ttotal: 1.83s\tremaining: 7.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.69828559606514e-07, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.69828559606514e-07, 'min_data_in_leaf': 13} scored 0.9961013645224172 in 0:00:02.810508\n",
            "Optimization Progress:  87%|████████▋ | 88/101 [04:05<00:30,  2.31s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 31.4ms\tremaining: 15.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 2.54s\tremaining: 10.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.518815523136767e-08, 'min_data_in_leaf': 8}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 6.518815523136767e-08, 'min_data_in_leaf': 8} scored 0.9961013645224172 in 0:00:03.168781\n",
            "Optimization Progress:  88%|████████▊ | 89/101 [04:08<00:30,  2.58s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 17.4ms\tremaining: 8.68s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9899749\tbest: 0.9919243 (57)\ttotal: 1.28s\tremaining: 5.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9919242551\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.9919242550821498 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0010210187889244525, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0010210187889244525, 'min_data_in_leaf': 12} scored 0.9919242550821498 in 0:00:02.245041\n",
            "Optimization Progress:  89%|████████▉ | 90/101 [04:10<00:27,  2.49s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.2ms\tremaining: 6.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9894180\tbest: 0.9958229 (25)\ttotal: 1.29s\tremaining: 5.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9958228906\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.9958228905597327 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.710824125189622e-06, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 9.710824125189622e-06, 'min_data_in_leaf': 10} scored 0.9958228905597327 in 0:00:02.353886\n",
            "Optimization Progress:  90%|█████████ | 91/101 [04:13<00:24,  2.46s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 16.2ms\tremaining: 8.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9924812\tbest: 0.9961014 (25)\ttotal: 1.3s\tremaining: 5.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.608777970418945e-06, 'min_data_in_leaf': 14}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.608777970418945e-06, 'min_data_in_leaf': 14} scored 0.9961013645224172 in 0:00:01.846295\n",
            "Optimization Progress:  91%|█████████ | 92/101 [04:15<00:20,  2.29s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 29.7ms\tremaining: 14.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9910888\tbest: 0.9961014 (25)\ttotal: 1.3s\tremaining: 5.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 8.158559946117967e-07, 'min_data_in_leaf': 17}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 8.158559946117967e-07, 'min_data_in_leaf': 17} scored 0.9961013645224172 in 0:00:01.863336\n",
            "Optimization Progress:  92%|█████████▏| 93/101 [04:17<00:17,  2.17s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.3ms\tremaining: 6.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9919243\tbest: 0.9961014 (25)\ttotal: 2.05s\tremaining: 8.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.348325820771022e-07, 'min_data_in_leaf': 14}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 5.348325820771022e-07, 'min_data_in_leaf': 14} scored 0.9961013645224172 in 0:00:03.003244\n",
            "Optimization Progress:  93%|█████████▎| 94/101 [04:20<00:17,  2.43s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 28.4ms\tremaining: 14.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9869117\tbest: 0.9922027 (59)\ttotal: 2.34s\tremaining: 9.23s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.992202729\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 59\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 60 iterations.\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.9922027290448343 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1022555798193312, 'min_data_in_leaf': 15}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.1022555798193312, 'min_data_in_leaf': 15} scored 0.9922027290448343 in 0:00:03.405284\n",
            "Optimization Progress:  94%|█████████▍| 95/101 [04:23<00:16,  2.73s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 12.6ms\tremaining: 6.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.32s\tremaining: 5.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.5846755723151537e-07, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.5846755723151537e-07, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.864224\n",
            "Optimization Progress:  95%|█████████▌| 96/101 [04:25<00:12,  2.48s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 18.5ms\tremaining: 9.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9869117\tbest: 0.9961014 (25)\ttotal: 1.34s\tremaining: 5.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.2964985280201067e-06, 'min_data_in_leaf': 11}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 3.2964985280201067e-06, 'min_data_in_leaf': 11} scored 0.9961013645224172 in 0:00:01.913373\n",
            "Optimization Progress:  96%|█████████▌| 97/101 [04:27<00:09,  2.32s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8010304\tbest: 0.8010304 (0)\ttotal: 10.1ms\tremaining: 5.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9746589\tbest: 0.9752158 (92)\ttotal: 836ms\tremaining: 3.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9896965\tbest: 0.9899749 (175)\ttotal: 1.67s\tremaining: 2.48s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9899749373\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 175\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 176 iterations.\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.9899749373433584 and parameters: {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0122705505571329e-06, 'min_data_in_leaf': 12}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0122705505571329e-06, 'min_data_in_leaf': 12} scored 0.9899749373433584 in 0:00:02.503211\n",
            "Optimization Progress:  97%|█████████▋| 98/101 [04:30<00:07,  2.39s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 21.7ms\tremaining: 10.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 1.3s\tremaining: 5.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.9722033495534107e-07, 'min_data_in_leaf': 10}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.9722033495534107e-07, 'min_data_in_leaf': 10} scored 0.9961013645224172 in 0:00:01.893119\n",
            "Optimization Progress:  98%|█████████▊| 99/101 [04:31<00:04,  2.25s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7173489\tbest: 0.7173489 (0)\ttotal: 3.44ms\tremaining: 1.72s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9579504\tbest: 0.9579504 (100)\ttotal: 292ms\tremaining: 1.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9743804\tbest: 0.9746589 (185)\ttotal: 704ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9766082\tbest: 0.9791145 (227)\ttotal: 1.53s\tremaining: 1.01s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9791144528\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 227\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 228 iterations.\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.9791144527986634 and parameters: {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 7.018898184960647e-07, 'min_data_in_leaf': 9}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 7.018898184960647e-07, 'min_data_in_leaf': 9} scored 0.9791144527986634 in 0:00:01.994783\n",
            "Optimization Progress:  99%|█████████▉| 100/101 [04:33<00:02,  2.18s/it, best_trial=37, best_value=0.996]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 23.3ms\tremaining: 11.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9913673\tbest: 0.9961014 (25)\ttotal: 2.76s\tremaining: 10.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9961013645\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 100 finished with value: 0.9961013645224172 and parameters: {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1550751465886109e-07, 'min_data_in_leaf': 13}. Best is trial 37 with value: 0.9961013645224172.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.1550751465886109e-07, 'min_data_in_leaf': 13} scored 0.9961013645224172 in 0:00:03.386994\n",
            "Optimization Progress: 100%|██████████| 101/101 [04:37<00:00,  2.75s/it, best_trial=37, best_value=0.996]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] The set of hyperparameters \u001b[1m{'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0988726118602128e-06, 'min_data_in_leaf': 9}\u001b[0m\n",
            " achieve 0.9961 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0988726118602128e-06, 'min_data_in_leaf': 9}\u001b[0m\n",
            " achieve 0.9961 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 1.0988726118602128e-06, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 7, 'min_data_in_leaf': 9, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Max', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:24] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7820941\tbest: 0.7820941 (0)\ttotal: 27.1ms\tremaining: 1m 21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9949875\tbest: 0.9966583 (40)\ttotal: 1.34s\tremaining: 38.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9966583124\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 40\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 41 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:26] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7613636\tbest: 0.7613636 (0)\ttotal: 12.1ms\tremaining: 36.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9404762\tbest: 0.9445346 (54)\ttotal: 1.27s\tremaining: 36.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9499459\tbest: 0.9515693 (185)\ttotal: 2.56s\tremaining: 35.7s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9529221\tbest: 0.9542749 (251)\ttotal: 3.83s\tremaining: 34.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9542748918\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 251\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 252 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:31] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8414502\tbest: 0.8414502 (0)\ttotal: 12ms\tremaining: 35.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9851190\tbest: 0.9862013 (90)\ttotal: 1.29s\tremaining: 37s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9932359\tbest: 0.9935065 (188)\ttotal: 2.56s\tremaining: 35.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9959416\tbest: 0.9959416 (282)\ttotal: 5.08s\tremaining: 45.6s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:400:\ttest: 0.9964827\tbest: 0.9964827 (394)\ttotal: 7.47s\tremaining: 48.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.996482684\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 394\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 395 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:40] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8188582\tbest: 0.8188582 (0)\ttotal: 13.4ms\tremaining: 40.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9916126\tbest: 0.9945887 (91)\ttotal: 1.3s\tremaining: 37.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9945887\tbest: 0.9956710 (158)\ttotal: 2.57s\tremaining: 35.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9956709957\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 158\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 159 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:43] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7490530\tbest: 0.7490530 (0)\ttotal: 12.3ms\tremaining: 36.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.9410173\tbest: 0.9439935 (75)\ttotal: 1.34s\tremaining: 38.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.9594156\tbest: 0.9594156 (200)\ttotal: 2.61s\tremaining: 36.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.9699675\tbest: 0.9699675 (283)\ttotal: 3.89s\tremaining: 34.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9699675325\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 283\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 284 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9652477715255935\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9652477715255935\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] Time left 2904.09 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 2904.09 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:48] Blending: optimization starts with equal weights. Score = \u001b[1m0.9812144\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.9812144\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9836851\u001b[0m, weights = \u001b[1m[0.         0.6150038  0.         0.13709708 0.2478991 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9836851\u001b[0m, weights = \u001b[1m[0.         0.6150038  0.         0.13709708 0.2478991 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9845231\u001b[0m, weights = \u001b[1m[0.06088624 0.50800323 0.12918998 0.         0.3019206 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9845231\u001b[0m, weights = \u001b[1m[0.06088624 0.50800323 0.12918998 0.         0.3019206 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9846211\u001b[0m, weights = \u001b[1m[0.06064685 0.60897934 0.         0.         0.3303738 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9846211\u001b[0m, weights = \u001b[1m[0.06064685 0.60897934 0.         0.         0.3303738 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Blending: best score = \u001b[1m0.9846211\u001b[0m, best weights = \u001b[1m[0.06064685 0.60897934 0.         0.         0.3303738 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.9846211\u001b[0m, best weights = \u001b[1m[0.06064685 0.60897934 0.         0.         0.3303738 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] \u001b[1mAutoml preset training completed in 696.58 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 696.58 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14:21:49] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.06065 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.60898 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.33037 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.06065 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.60898 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
            "\t 0.33037 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = automl.predict(test_data)"
      ],
      "metadata": {
        "id": "O8qDGIC_k7xH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'OOF score: {roc_auc_score(train_data[TARGET_NAME].values, out_of_fold_predictions.data[:, 0])}')\n",
        "print(f'HOLDOUT score: {roc_auc_score(test_data[TARGET_NAME].values, test_predictions.data[:, 0])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP8zGu6ClFAp",
        "outputId": "8d30d3e1-f1a4-4acd-bb4f-ab3b0f0c52e3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF score: 0.9846210777217862\n",
            "HOLDOUT score: 0.9944588744588745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (test_predictions.data[:, 0] > 0.1)*1\n",
        "print(classification_report(test_data[TARGET_NAME].values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hnJdb3_lFxG",
        "outputId": "9f4b7af2-ce0c-49d8-bc92-beb8db4f1ac4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94       165\n",
            "           1       0.64      1.00      0.78        35\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.82      0.94      0.86       200\n",
            "weighted avg       0.94      0.90      0.91       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['pred'] = y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhhazcCw5VaL",
        "outputId": "210b0174-4be2-4d5f-c23a-8254ee84922d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4107617879.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  test_data['pred'] = y_pred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_data[test_data['pred'] == 1]\n",
        "test.sort_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "clUKVif55aaq",
        "outputId": "528cc74a-a97f-41ab-a326-3cb56c471ead"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Open    High     Low   Close     Volume  diff  \\\n",
              "Date                                                                   \n",
              "2022-12-09 16:00:00  289.81  290.45  284.60  289.24   9010.436    -1   \n",
              "2022-12-18 16:00:00  245.30  253.70  244.44  246.91  25681.862    12   \n",
              "2022-12-21 16:00:00  249.01  249.12  240.40  241.07  12766.152    12   \n",
              "2022-12-25 16:00:00  243.45  245.00  241.22  242.57  11257.776    11   \n",
              "2023-01-03 16:00:00  245.56  258.04  244.32  256.89  18535.416     4   \n",
              "2023-01-04 16:00:00  256.95  261.15  254.98  256.98  16231.547     2   \n",
              "2023-01-30 16:00:00  308.70  315.08  302.40  312.50  21165.823    -7   \n",
              "2023-02-17 16:00:00  310.20  319.00  307.30  316.79  31205.315     1   \n",
              "2023-02-19 16:00:00  316.90  319.60  308.40  317.40  30629.878    -1   \n",
              "2023-02-27 16:00:00  304.90  305.60  300.60  304.50  12909.797     3   \n",
              "2023-03-01 16:00:00  303.20  304.04  296.00  297.70  12736.040     3   \n",
              "2023-03-10 16:00:00  274.40  281.60  271.40  272.20  30174.725     6   \n",
              "2023-03-11 16:00:00  272.10  278.40  270.59  273.70  17007.122     6   \n",
              "2023-03-12 16:00:00  273.60  312.80  273.40  309.06  66806.191     5   \n",
              "2023-03-13 16:00:00  308.79  319.60  302.01  318.40  40540.259     3   \n",
              "2023-04-14 16:00:00  325.84  335.97  323.38  334.10  27853.080    -2   \n",
              "2023-05-30 16:00:00  311.84  313.03  305.18  305.25  20412.211     1   \n",
              "2023-06-02 16:00:00  306.16  308.19  305.25  307.85   8655.593     1   \n",
              "2023-06-03 16:00:00  307.82  308.11  305.45  306.53   7475.461     1   \n",
              "2023-06-04 16:00:00  306.52  307.38  276.78  276.94  31075.859     3   \n",
              "2023-06-09 16:00:00  261.27  262.61  228.94  235.32  79202.195    13   \n",
              "2023-06-30 16:00:00  235.48  248.64  234.81  247.33  35624.030     5   \n",
              "2023-07-02 16:00:00  246.03  254.55  243.31  249.44  38290.058     2   \n",
              "2023-07-08 16:00:00  236.64  237.00  233.20  234.44  13506.295     1   \n",
              "2023-09-19 16:00:00  218.32  218.52  214.80  215.89   9989.093    -1   \n",
              "2023-10-21 16:00:00  214.25  216.70  213.60  214.21  18315.530    -1   \n",
              "2024-01-09 16:00:00  301.10  302.99  289.07  294.60  34026.908    -6   \n",
              "2024-01-12 16:00:00  305.63  306.88  289.86  302.22  29153.177    -4   \n",
              "2024-01-17 16:00:00  312.17  315.38  305.71  315.21  31396.007    -4   \n",
              "2024-01-20 16:00:00  314.06  319.47  313.90  318.62  13344.530    -3   \n",
              "2024-01-29 16:00:00  308.48  313.02  307.51  309.19  22411.424     1   \n",
              "2024-01-31 16:00:00  304.71  305.57  296.53  299.81  18862.881     1   \n",
              "2024-02-02 16:00:00  302.56  303.73  299.71  300.46   9153.086     1   \n",
              "2024-04-22 16:00:00  595.03  613.79  593.50  604.02  17078.807     0   \n",
              "2024-05-14 16:00:00  569.76  582.31  561.50  579.96   7781.089    -1   \n",
              "2024-05-17 16:00:00  582.46  583.15  574.50  577.54   3321.004     2   \n",
              "2024-05-18 16:00:00  577.58  581.64  575.00  577.58   3046.259     1   \n",
              "2024-05-19 16:00:00  577.56  580.03  569.12  576.65   3686.110     2   \n",
              "2024-05-20 16:00:00  576.60  630.79  575.47  612.80  19410.165     0   \n",
              "2024-08-26 16:00:00  558.22  561.61  547.02  552.02   3006.269    -6   \n",
              "2024-08-28 16:00:00  533.29  545.47  523.01  541.70   2418.163    -3   \n",
              "2024-09-11 16:00:00  517.72  548.11  517.69  535.45   3914.348     4   \n",
              "2024-09-12 16:00:00  535.44  554.21  534.90  553.69   3109.708     2   \n",
              "2024-09-18 16:00:00  538.05  567.63  537.50  565.22   3829.966    -2   \n",
              "2024-10-05 16:00:00  564.08  569.00  558.01  567.50   1174.840     1   \n",
              "2024-10-15 16:00:00  589.25  600.99  587.19  595.46   2595.866    -1   \n",
              "2024-10-29 16:00:00  609.84  612.00  594.45  597.10   2891.387    -2   \n",
              "2024-10-31 16:00:00  580.18  585.21  569.27  572.01   2827.593    -1   \n",
              "2024-11-04 16:00:00  559.70  569.84  544.00  564.25   3010.971     3   \n",
              "2024-11-06 16:00:00  583.17  611.00  582.00  597.50   4616.260     2   \n",
              "2025-01-09 16:00:00  696.93  698.70  675.76  693.10   2767.821     0   \n",
              "2025-01-13 16:00:00  677.29  698.23  666.49  695.17   2157.882     1   \n",
              "2025-04-20 16:00:00  588.17  608.51  587.50  604.06   1560.883     1   \n",
              "2025-04-21 16:00:00  604.03  612.20  594.50  609.78   3290.598     0   \n",
              "2025-07-02 16:00:00  661.64  664.83  656.70  657.06   1559.197    -1   \n",
              "\n",
              "                     diff_shift  target  diff_high_low  diff_open_close  ...  \\\n",
              "Date                                                                     ...   \n",
              "2022-12-09 16:00:00         0.0       1        58500.0           5700.0  ...   \n",
              "2022-12-18 16:00:00        10.0       1        92600.0         -16100.0  ...   \n",
              "2022-12-21 16:00:00        12.0       1        87200.0          79400.0  ...   \n",
              "2022-12-25 16:00:00        11.0       1        37800.0           8800.0  ...   \n",
              "2023-01-03 16:00:00         5.0       1       137200.0        -113300.0  ...   \n",
              "2023-01-04 16:00:00         4.0       1        61700.0           -300.0  ...   \n",
              "2023-01-30 16:00:00        -8.0       0       126800.0         -38000.0  ...   \n",
              "2023-02-17 16:00:00         2.0       0       117000.0         -65900.0  ...   \n",
              "2023-02-19 16:00:00         0.0       1       112000.0          -5000.0  ...   \n",
              "2023-02-27 16:00:00         3.0       1        50000.0           4000.0  ...   \n",
              "2023-03-01 16:00:00         3.0       1        80400.0          55000.0  ...   \n",
              "2023-03-10 16:00:00         5.0       1       102000.0          22000.0  ...   \n",
              "2023-03-11 16:00:00         6.0       1        78100.0         -16000.0  ...   \n",
              "2023-03-12 16:00:00         6.0       1       394000.0        -354600.0  ...   \n",
              "2023-03-13 16:00:00         5.0       1       175900.0         -96100.0  ...   \n",
              "2023-04-14 16:00:00         0.0       1       125900.0         -82600.0  ...   \n",
              "2023-05-30 16:00:00         1.0       0        78500.0          65900.0  ...   \n",
              "2023-06-02 16:00:00         1.0       0        29400.0         -16900.0  ...   \n",
              "2023-06-03 16:00:00         1.0       0        26600.0          12900.0  ...   \n",
              "2023-06-04 16:00:00         1.0       0       306000.0         295800.0  ...   \n",
              "2023-06-09 16:00:00        11.0       0       336700.0         259500.0  ...   \n",
              "2023-06-30 16:00:00         7.0       0       138300.0        -118500.0  ...   \n",
              "2023-07-02 16:00:00         4.0       0       112400.0         -34100.0  ...   \n",
              "2023-07-08 16:00:00         1.0       1        38000.0          22000.0  ...   \n",
              "2023-09-19 16:00:00         0.0       1        37200.0          24300.0  ...   \n",
              "2023-10-21 16:00:00         0.0       1        31000.0            400.0  ...   \n",
              "2024-01-09 16:00:00        -8.0       1       139200.0          65000.0  ...   \n",
              "2024-01-12 16:00:00        -5.0       1       170200.0          34100.0  ...   \n",
              "2024-01-17 16:00:00        -4.0       1        96700.0         -30400.0  ...   \n",
              "2024-01-20 16:00:00        -3.0       1        55700.0         -45600.0  ...   \n",
              "2024-01-29 16:00:00         2.0       1        55100.0          -7100.0  ...   \n",
              "2024-01-31 16:00:00         0.0       1        90400.0          49000.0  ...   \n",
              "2024-02-02 16:00:00         1.0       1        40200.0          21000.0  ...   \n",
              "2024-04-22 16:00:00         1.0       0       202900.0         -89900.0  ...   \n",
              "2024-05-14 16:00:00        -1.0       0       208100.0        -102000.0  ...   \n",
              "2024-05-17 16:00:00         1.0       0        86500.0          49200.0  ...   \n",
              "2024-05-18 16:00:00         2.0       0        66400.0              0.0  ...   \n",
              "2024-05-19 16:00:00         1.0       0       109100.0           9100.0  ...   \n",
              "2024-05-20 16:00:00         2.0       0       553200.0        -362000.0  ...   \n",
              "2024-08-26 16:00:00        -7.0       0       145900.0          62000.0  ...   \n",
              "2024-08-28 16:00:00        -4.0       1       224600.0         -84100.0  ...   \n",
              "2024-09-11 16:00:00         5.0       1       304200.0        -177300.0  ...   \n",
              "2024-09-12 16:00:00         4.0       1       193100.0        -182500.0  ...   \n",
              "2024-09-18 16:00:00        -2.0       0       301300.0        -271700.0  ...   \n",
              "2024-10-05 16:00:00         0.0       0       109900.0         -34200.0  ...   \n",
              "2024-10-15 16:00:00        -1.0       1       138000.0         -62100.0  ...   \n",
              "2024-10-29 16:00:00        -2.0       1       175500.0         127400.0  ...   \n",
              "2024-10-31 16:00:00        -2.0       1       159400.0          81700.0  ...   \n",
              "2024-11-04 16:00:00         3.0       1       258400.0         -45500.0  ...   \n",
              "2024-11-06 16:00:00         3.0       1       290000.0        -143300.0  ...   \n",
              "2025-01-09 16:00:00        -1.0       1       229400.0          38300.0  ...   \n",
              "2025-01-13 16:00:00         1.0       1       317400.0        -178800.0  ...   \n",
              "2025-04-20 16:00:00         1.0       0       210100.0        -158900.0  ...   \n",
              "2025-04-21 16:00:00         1.0       0       177000.0         -57500.0  ...   \n",
              "2025-07-02 16:00:00         0.0       1        81300.0          45800.0  ...   \n",
              "\n",
              "                       BB_lower  volatility_7  volatility_14  volatility_21  \\\n",
              "Date                                                                          \n",
              "2022-12-09 16:00:00  266.276576      2.358932       7.281678      13.061027   \n",
              "2022-12-18 16:00:00  239.096196     14.570248      19.365109      19.190957   \n",
              "2022-12-21 16:00:00  229.637595      5.048808      19.228338      20.214920   \n",
              "2022-12-25 16:00:00  221.880178      3.626462      11.364176      19.942109   \n",
              "2023-01-03 16:00:00  237.575277      4.222998       3.702699       5.470791   \n",
              "2023-01-04 16:00:00  236.621187      5.449481       4.570513       4.653313   \n",
              "2023-01-30 16:00:00  283.082900      5.982321       8.576927      10.474144   \n",
              "2023-02-17 16:00:00  290.660596     12.648809      12.905680      12.232950   \n",
              "2023-02-19 16:00:00  291.600798      9.361803      11.569560      12.121832   \n",
              "2023-02-27 16:00:00  291.138495      2.307545       7.030863       9.275965   \n",
              "2023-03-01 16:00:00  290.051176      2.557808       6.282303       8.316669   \n",
              "2023-03-10 16:00:00  273.062572      8.163420      10.383972      12.423765   \n",
              "2023-03-11 16:00:00  270.786008      8.652498      10.798850      12.661473   \n",
              "2023-03-12 16:00:00  271.154458     13.311543      11.291862      12.066102   \n",
              "2023-03-13 16:00:00  269.859893     18.274058      13.117784      12.516702   \n",
              "2023-04-14 16:00:00  302.704106      8.643153       7.960070       6.971658   \n",
              "2023-05-30 16:00:00  302.822852      3.539632       3.170112       3.227502   \n",
              "2023-06-02 16:00:00  302.482480      3.257401       3.267483       3.346529   \n",
              "2023-06-03 16:00:00  302.648884      3.315941       3.273426       3.185222   \n",
              "2023-06-04 16:00:00  291.618074     11.630279       8.843100       7.456650   \n",
              "2023-06-09 16:00:00  248.610364     21.923560      25.286724      22.517708   \n",
              "2023-06-30 16:00:00  228.333794      4.597713       5.577526       5.654892   \n",
              "2023-07-02 16:00:00  229.909323      6.730270       5.987682       5.695154   \n",
              "2023-07-08 16:00:00  229.216933      5.306584       5.197092       5.323886   \n",
              "2023-09-19 16:00:00  208.972044      2.697971       3.089528       2.970163   \n",
              "2023-10-21 16:00:00  204.299927      1.381530       3.346455       3.245658   \n",
              "2024-01-09 16:00:00  264.837410      8.430595       8.996366      19.294613   \n",
              "2024-01-12 16:00:00  281.964395      4.266991       7.063342      14.826511   \n",
              "2024-01-17 16:00:00  295.866620      5.761918       6.451084       6.742311   \n",
              "2024-01-20 16:00:00  295.930539      2.573414       7.148322       6.650086   \n",
              "2024-01-29 16:00:00  292.795870      6.515666       7.975152       7.610453   \n",
              "2024-01-31 16:00:00  291.963475      3.244913       7.563010       7.288480   \n",
              "2024-02-02 16:00:00  291.499824      3.655351       6.914372       7.408047   \n",
              "2024-04-22 16:00:00  525.734379     28.766667      29.558462      24.938808   \n",
              "2024-05-14 16:00:00  555.310155      9.982605      10.064557      15.474033   \n",
              "2024-05-17 16:00:00  553.769727     11.051576       9.484157      14.427846   \n",
              "2024-05-18 16:00:00  553.438731      9.108956       9.478934      13.628425   \n",
              "2024-05-19 16:00:00  555.791182      5.246773       9.619343      13.435367   \n",
              "2024-05-20 16:00:00  561.787066     14.236625      12.117573      14.344317   \n",
              "2024-08-26 16:00:00  487.296238     12.874500      21.624881      28.784586   \n",
              "2024-08-28 16:00:00  498.232380     18.816417      20.278528      24.018605   \n",
              "2024-09-11 16:00:00  476.244989     15.816497      14.338604      27.221710   \n",
              "2024-09-12 16:00:00  479.402212     21.672734      17.775524      25.217682   \n",
              "2024-09-18 16:00:00  480.737136     10.956573      25.732183      22.130592   \n",
              "2024-10-05 16:00:00  529.841146     10.796935      23.689185      23.817098   \n",
              "2024-10-15 16:00:00  539.852141     11.871401      14.352785      18.164364   \n",
              "2024-10-29 16:00:00  568.986155      9.063669       7.902777      11.525641   \n",
              "2024-10-31 16:00:00  569.734268     12.502329       9.936301      10.434623   \n",
              "2024-11-04 16:00:00  554.352682     14.828379      15.946364      15.248226   \n",
              "2024-11-06 16:00:00  554.231471     15.311957      16.309407      15.212357   \n",
              "2025-01-09 16:00:00  668.418313     11.646679       9.731789      17.074058   \n",
              "2025-01-13 16:00:00  678.635533      6.769370      11.549119      11.388156   \n",
              "2025-04-20 16:00:00  556.110386      6.910518      12.931476      15.319416   \n",
              "2025-04-21 16:00:00  555.505360      9.440189      12.600228      14.832490   \n",
              "2025-07-02 16:00:00  620.076504      6.355826      13.891377      11.889614   \n",
              "\n",
              "                     daily_return  high_low_ratio  close_open_ratio  \\\n",
              "Date                                                                  \n",
              "2022-12-09 16:00:00     -0.001829        1.020555          0.998033   \n",
              "2022-12-18 16:00:00      0.006604        1.037883          1.006563   \n",
              "2022-12-21 16:00:00     -0.031886        1.036273          0.968114   \n",
              "2022-12-25 16:00:00     -0.003615        1.015670          0.996385   \n",
              "2023-01-03 16:00:00      0.046139        1.056156          1.046139   \n",
              "2023-01-04 16:00:00      0.000350        1.024198          1.000117   \n",
              "2023-01-30 16:00:00      0.012310        1.041931          1.012310   \n",
              "2023-02-17 16:00:00      0.021574        1.038074          1.021244   \n",
              "2023-02-19 16:00:00      0.000694        1.036316          1.001578   \n",
              "2023-02-27 16:00:00     -0.001312        1.016633          0.998688   \n",
              "2023-03-01 16:00:00     -0.018464        1.027162          0.981860   \n",
              "2023-03-10 16:00:00     -0.008017        1.037583          0.991983   \n",
              "2023-03-11 16:00:00      0.005511        1.028863          1.005880   \n",
              "2023-03-12 16:00:00      0.129193        1.144111          1.129605   \n",
              "2023-03-13 16:00:00      0.030221        1.058243          1.031121   \n",
              "2023-04-14 16:00:00      0.025224        1.038933          1.025350   \n",
              "2023-05-30 16:00:00     -0.021258        1.025723          0.978867   \n",
              "2023-06-02 16:00:00      0.005553        1.009631          1.005520   \n",
              "2023-06-03 16:00:00     -0.004288        1.008708          0.995809   \n",
              "2023-06-04 16:00:00     -0.096532        1.110557          0.903497   \n",
              "2023-06-09 16:00:00     -0.099116        1.147069          0.900677   \n",
              "2023-06-30 16:00:00      0.050189        1.058899          1.050323   \n",
              "2023-07-02 16:00:00      0.013736        1.046196          1.013860   \n",
              "2023-07-08 16:00:00     -0.009171        1.016295          0.990703   \n",
              "2023-09-19 16:00:00     -0.010813        1.017318          0.988870   \n",
              "2023-10-21 16:00:00     -0.000233        1.014513          0.999813   \n",
              "2024-01-09 16:00:00     -0.021652        1.048154          0.978412   \n",
              "2024-01-12 16:00:00     -0.011222        1.058718          0.988843   \n",
              "2024-01-17 16:00:00      0.009965        1.031631          1.009738   \n",
              "2024-01-20 16:00:00      0.014746        1.017745          1.014520   \n",
              "2024-01-29 16:00:00      0.002237        1.017918          1.002302   \n",
              "2024-01-31 16:00:00     -0.016113        1.030486          0.983919   \n",
              "2024-02-02 16:00:00     -0.006974        1.013413          0.993059   \n",
              "2024-04-22 16:00:00      0.015108        1.034187          1.015108   \n",
              "2024-05-14 16:00:00      0.017867        1.037061          1.017902   \n",
              "2024-05-17 16:00:00     -0.008481        1.015057          0.991553   \n",
              "2024-05-18 16:00:00      0.000069        1.011548          1.000000   \n",
              "2024-05-19 16:00:00     -0.001610        1.019170          0.998424   \n",
              "2024-05-20 16:00:00      0.062690        1.096130          1.062782   \n",
              "2024-08-26 16:00:00     -0.011426        1.026672          0.988893   \n",
              "2024-08-28 16:00:00      0.015656        1.042944          1.015770   \n",
              "2024-09-11 16:00:00      0.033687        1.058761          1.034246   \n",
              "2024-09-12 16:00:00      0.034065        1.036100          1.034084   \n",
              "2024-09-18 16:00:00      0.050321        1.056056          1.050497   \n",
              "2024-10-05 16:00:00      0.006045        1.019695          1.006063   \n",
              "2024-10-15 16:00:00      0.010505        1.023502          1.010539   \n",
              "2024-10-29 16:00:00     -0.020891        1.029523          0.979109   \n",
              "2024-10-31 16:00:00     -0.014099        1.028001          0.985918   \n",
              "2024-11-04 16:00:00      0.008075        1.047500          1.008129   \n",
              "2024-11-06 16:00:00      0.024608        1.049828          1.024573   \n",
              "2025-01-09 16:00:00     -0.005510        1.033947          0.994504   \n",
              "2025-01-13 16:00:00      0.026399        1.047623          1.026399   \n",
              "2025-04-20 16:00:00      0.026964        1.035762          1.027016   \n",
              "2025-04-21 16:00:00      0.009469        1.029773          1.009519   \n",
              "2025-07-02 16:00:00     -0.006922        1.012380          0.993078   \n",
              "\n",
              "                      volume_ma_7  volume_ratio  pred  \n",
              "Date                                                   \n",
              "2022-12-09 16:00:00  16504.869714      0.545926     1  \n",
              "2022-12-18 16:00:00  18244.180000      1.407674     1  \n",
              "2022-12-21 16:00:00  14884.852857      0.857661     1  \n",
              "2022-12-25 16:00:00  13112.460286      0.858556     1  \n",
              "2023-01-03 16:00:00  11946.235286      1.551570     1  \n",
              "2023-01-04 16:00:00  12484.423429      1.300144     1  \n",
              "2023-01-30 16:00:00  23633.616714      0.895581     1  \n",
              "2023-02-17 16:00:00  39021.241000      0.799701     1  \n",
              "2023-02-19 16:00:00  35956.014857      0.851871     1  \n",
              "2023-02-27 16:00:00  15397.582714      0.838430     1  \n",
              "2023-03-01 16:00:00  13996.643286      0.909935     1  \n",
              "2023-03-10 16:00:00  18687.606143      1.614692     1  \n",
              "2023-03-11 16:00:00  19616.116000      0.866997     1  \n",
              "2023-03-12 16:00:00  27980.720714      2.387579     1  \n",
              "2023-03-13 16:00:00  31675.868714      1.279847     1  \n",
              "2023-04-14 16:00:00  22662.688857      1.229028     1  \n",
              "2023-05-30 16:00:00  15153.993714      1.346986     1  \n",
              "2023-06-02 16:00:00  14375.985286      0.602087     1  \n",
              "2023-06-03 16:00:00  14417.896429      0.518485     1  \n",
              "2023-06-04 16:00:00  15531.958000      2.000769     1  \n",
              "2023-06-09 16:00:00  43547.316571      1.818762     1  \n",
              "2023-06-30 16:00:00  28889.284000      1.233123     1  \n",
              "2023-07-02 16:00:00  30751.558000      1.245142     1  \n",
              "2023-07-08 16:00:00  25013.456286      0.539961     1  \n",
              "2023-09-19 16:00:00  11478.403571      0.870251     1  \n",
              "2023-10-21 16:00:00  18130.187571      1.010223     1  \n",
              "2024-01-09 16:00:00  43812.141286      0.776655     1  \n",
              "2024-01-12 16:00:00  36693.425143      0.794507     1  \n",
              "2024-01-17 16:00:00  37302.934286      0.841650     1  \n",
              "2024-01-20 16:00:00  36134.023714      0.369307     1  \n",
              "2024-01-29 16:00:00  29232.507286      0.766661     1  \n",
              "2024-01-31 16:00:00  22701.072571      0.830925     1  \n",
              "2024-02-02 16:00:00  17790.227714      0.514501     1  \n",
              "2024-04-22 16:00:00  18825.813857      0.907202     1  \n",
              "2024-05-14 16:00:00   6809.246429      1.142724     1  \n",
              "2024-05-17 16:00:00   6193.464571      0.536211     1  \n",
              "2024-05-18 16:00:00   6187.932571      0.492290     1  \n",
              "2024-05-19 16:00:00   5608.420857      0.657246     1  \n",
              "2024-05-20 16:00:00   7305.472571      2.656935     1  \n",
              "2024-08-26 16:00:00   3811.171000      0.788805     1  \n",
              "2024-08-28 16:00:00   3323.683857      0.727555     1  \n",
              "2024-09-11 16:00:00   2531.869000      1.546031     1  \n",
              "2024-09-12 16:00:00   2583.729714      1.203573     1  \n",
              "2024-09-18 16:00:00   2632.266857      1.455007     1  \n",
              "2024-10-05 16:00:00   2746.882143      0.427699     1  \n",
              "2024-10-15 16:00:00   2230.121429      1.164002     1  \n",
              "2024-10-29 16:00:00   2016.186857      1.434087     1  \n",
              "2024-10-31 16:00:00   2277.333000      1.241625     1  \n",
              "2024-11-04 16:00:00   2504.994857      1.201987     1  \n",
              "2024-11-06 16:00:00   3288.258000      1.403862     1  \n",
              "2025-01-09 16:00:00   3317.385143      0.834338     1  \n",
              "2025-01-13 16:00:00   2831.503143      0.762098     1  \n",
              "2025-04-20 16:00:00   1511.546857      1.032640     1  \n",
              "2025-04-21 16:00:00   1778.629857      1.850075     1  \n",
              "2025-07-02 16:00:00   1173.820857      1.328309     1  \n",
              "\n",
              "[55 rows x 176 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa30dbb6-f700-48b9-a77c-38023743f886\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>diff</th>\n",
              "      <th>diff_shift</th>\n",
              "      <th>target</th>\n",
              "      <th>diff_high_low</th>\n",
              "      <th>diff_open_close</th>\n",
              "      <th>...</th>\n",
              "      <th>BB_lower</th>\n",
              "      <th>volatility_7</th>\n",
              "      <th>volatility_14</th>\n",
              "      <th>volatility_21</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>high_low_ratio</th>\n",
              "      <th>close_open_ratio</th>\n",
              "      <th>volume_ma_7</th>\n",
              "      <th>volume_ratio</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-12-09 16:00:00</th>\n",
              "      <td>289.81</td>\n",
              "      <td>290.45</td>\n",
              "      <td>284.60</td>\n",
              "      <td>289.24</td>\n",
              "      <td>9010.436</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>58500.0</td>\n",
              "      <td>5700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>266.276576</td>\n",
              "      <td>2.358932</td>\n",
              "      <td>7.281678</td>\n",
              "      <td>13.061027</td>\n",
              "      <td>-0.001829</td>\n",
              "      <td>1.020555</td>\n",
              "      <td>0.998033</td>\n",
              "      <td>16504.869714</td>\n",
              "      <td>0.545926</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-18 16:00:00</th>\n",
              "      <td>245.30</td>\n",
              "      <td>253.70</td>\n",
              "      <td>244.44</td>\n",
              "      <td>246.91</td>\n",
              "      <td>25681.862</td>\n",
              "      <td>12</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>92600.0</td>\n",
              "      <td>-16100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>239.096196</td>\n",
              "      <td>14.570248</td>\n",
              "      <td>19.365109</td>\n",
              "      <td>19.190957</td>\n",
              "      <td>0.006604</td>\n",
              "      <td>1.037883</td>\n",
              "      <td>1.006563</td>\n",
              "      <td>18244.180000</td>\n",
              "      <td>1.407674</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-21 16:00:00</th>\n",
              "      <td>249.01</td>\n",
              "      <td>249.12</td>\n",
              "      <td>240.40</td>\n",
              "      <td>241.07</td>\n",
              "      <td>12766.152</td>\n",
              "      <td>12</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>87200.0</td>\n",
              "      <td>79400.0</td>\n",
              "      <td>...</td>\n",
              "      <td>229.637595</td>\n",
              "      <td>5.048808</td>\n",
              "      <td>19.228338</td>\n",
              "      <td>20.214920</td>\n",
              "      <td>-0.031886</td>\n",
              "      <td>1.036273</td>\n",
              "      <td>0.968114</td>\n",
              "      <td>14884.852857</td>\n",
              "      <td>0.857661</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-25 16:00:00</th>\n",
              "      <td>243.45</td>\n",
              "      <td>245.00</td>\n",
              "      <td>241.22</td>\n",
              "      <td>242.57</td>\n",
              "      <td>11257.776</td>\n",
              "      <td>11</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37800.0</td>\n",
              "      <td>8800.0</td>\n",
              "      <td>...</td>\n",
              "      <td>221.880178</td>\n",
              "      <td>3.626462</td>\n",
              "      <td>11.364176</td>\n",
              "      <td>19.942109</td>\n",
              "      <td>-0.003615</td>\n",
              "      <td>1.015670</td>\n",
              "      <td>0.996385</td>\n",
              "      <td>13112.460286</td>\n",
              "      <td>0.858556</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-03 16:00:00</th>\n",
              "      <td>245.56</td>\n",
              "      <td>258.04</td>\n",
              "      <td>244.32</td>\n",
              "      <td>256.89</td>\n",
              "      <td>18535.416</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>137200.0</td>\n",
              "      <td>-113300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>237.575277</td>\n",
              "      <td>4.222998</td>\n",
              "      <td>3.702699</td>\n",
              "      <td>5.470791</td>\n",
              "      <td>0.046139</td>\n",
              "      <td>1.056156</td>\n",
              "      <td>1.046139</td>\n",
              "      <td>11946.235286</td>\n",
              "      <td>1.551570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04 16:00:00</th>\n",
              "      <td>256.95</td>\n",
              "      <td>261.15</td>\n",
              "      <td>254.98</td>\n",
              "      <td>256.98</td>\n",
              "      <td>16231.547</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>61700.0</td>\n",
              "      <td>-300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>236.621187</td>\n",
              "      <td>5.449481</td>\n",
              "      <td>4.570513</td>\n",
              "      <td>4.653313</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>1.024198</td>\n",
              "      <td>1.000117</td>\n",
              "      <td>12484.423429</td>\n",
              "      <td>1.300144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-30 16:00:00</th>\n",
              "      <td>308.70</td>\n",
              "      <td>315.08</td>\n",
              "      <td>302.40</td>\n",
              "      <td>312.50</td>\n",
              "      <td>21165.823</td>\n",
              "      <td>-7</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>126800.0</td>\n",
              "      <td>-38000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>283.082900</td>\n",
              "      <td>5.982321</td>\n",
              "      <td>8.576927</td>\n",
              "      <td>10.474144</td>\n",
              "      <td>0.012310</td>\n",
              "      <td>1.041931</td>\n",
              "      <td>1.012310</td>\n",
              "      <td>23633.616714</td>\n",
              "      <td>0.895581</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-17 16:00:00</th>\n",
              "      <td>310.20</td>\n",
              "      <td>319.00</td>\n",
              "      <td>307.30</td>\n",
              "      <td>316.79</td>\n",
              "      <td>31205.315</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>117000.0</td>\n",
              "      <td>-65900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>290.660596</td>\n",
              "      <td>12.648809</td>\n",
              "      <td>12.905680</td>\n",
              "      <td>12.232950</td>\n",
              "      <td>0.021574</td>\n",
              "      <td>1.038074</td>\n",
              "      <td>1.021244</td>\n",
              "      <td>39021.241000</td>\n",
              "      <td>0.799701</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-19 16:00:00</th>\n",
              "      <td>316.90</td>\n",
              "      <td>319.60</td>\n",
              "      <td>308.40</td>\n",
              "      <td>317.40</td>\n",
              "      <td>30629.878</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>112000.0</td>\n",
              "      <td>-5000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>291.600798</td>\n",
              "      <td>9.361803</td>\n",
              "      <td>11.569560</td>\n",
              "      <td>12.121832</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>1.036316</td>\n",
              "      <td>1.001578</td>\n",
              "      <td>35956.014857</td>\n",
              "      <td>0.851871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-27 16:00:00</th>\n",
              "      <td>304.90</td>\n",
              "      <td>305.60</td>\n",
              "      <td>300.60</td>\n",
              "      <td>304.50</td>\n",
              "      <td>12909.797</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>291.138495</td>\n",
              "      <td>2.307545</td>\n",
              "      <td>7.030863</td>\n",
              "      <td>9.275965</td>\n",
              "      <td>-0.001312</td>\n",
              "      <td>1.016633</td>\n",
              "      <td>0.998688</td>\n",
              "      <td>15397.582714</td>\n",
              "      <td>0.838430</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 16:00:00</th>\n",
              "      <td>303.20</td>\n",
              "      <td>304.04</td>\n",
              "      <td>296.00</td>\n",
              "      <td>297.70</td>\n",
              "      <td>12736.040</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>80400.0</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>290.051176</td>\n",
              "      <td>2.557808</td>\n",
              "      <td>6.282303</td>\n",
              "      <td>8.316669</td>\n",
              "      <td>-0.018464</td>\n",
              "      <td>1.027162</td>\n",
              "      <td>0.981860</td>\n",
              "      <td>13996.643286</td>\n",
              "      <td>0.909935</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-10 16:00:00</th>\n",
              "      <td>274.40</td>\n",
              "      <td>281.60</td>\n",
              "      <td>271.40</td>\n",
              "      <td>272.20</td>\n",
              "      <td>30174.725</td>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>102000.0</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>273.062572</td>\n",
              "      <td>8.163420</td>\n",
              "      <td>10.383972</td>\n",
              "      <td>12.423765</td>\n",
              "      <td>-0.008017</td>\n",
              "      <td>1.037583</td>\n",
              "      <td>0.991983</td>\n",
              "      <td>18687.606143</td>\n",
              "      <td>1.614692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-11 16:00:00</th>\n",
              "      <td>272.10</td>\n",
              "      <td>278.40</td>\n",
              "      <td>270.59</td>\n",
              "      <td>273.70</td>\n",
              "      <td>17007.122</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>78100.0</td>\n",
              "      <td>-16000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>270.786008</td>\n",
              "      <td>8.652498</td>\n",
              "      <td>10.798850</td>\n",
              "      <td>12.661473</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>1.028863</td>\n",
              "      <td>1.005880</td>\n",
              "      <td>19616.116000</td>\n",
              "      <td>0.866997</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-12 16:00:00</th>\n",
              "      <td>273.60</td>\n",
              "      <td>312.80</td>\n",
              "      <td>273.40</td>\n",
              "      <td>309.06</td>\n",
              "      <td>66806.191</td>\n",
              "      <td>5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>394000.0</td>\n",
              "      <td>-354600.0</td>\n",
              "      <td>...</td>\n",
              "      <td>271.154458</td>\n",
              "      <td>13.311543</td>\n",
              "      <td>11.291862</td>\n",
              "      <td>12.066102</td>\n",
              "      <td>0.129193</td>\n",
              "      <td>1.144111</td>\n",
              "      <td>1.129605</td>\n",
              "      <td>27980.720714</td>\n",
              "      <td>2.387579</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-13 16:00:00</th>\n",
              "      <td>308.79</td>\n",
              "      <td>319.60</td>\n",
              "      <td>302.01</td>\n",
              "      <td>318.40</td>\n",
              "      <td>40540.259</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>175900.0</td>\n",
              "      <td>-96100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>269.859893</td>\n",
              "      <td>18.274058</td>\n",
              "      <td>13.117784</td>\n",
              "      <td>12.516702</td>\n",
              "      <td>0.030221</td>\n",
              "      <td>1.058243</td>\n",
              "      <td>1.031121</td>\n",
              "      <td>31675.868714</td>\n",
              "      <td>1.279847</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-14 16:00:00</th>\n",
              "      <td>325.84</td>\n",
              "      <td>335.97</td>\n",
              "      <td>323.38</td>\n",
              "      <td>334.10</td>\n",
              "      <td>27853.080</td>\n",
              "      <td>-2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>125900.0</td>\n",
              "      <td>-82600.0</td>\n",
              "      <td>...</td>\n",
              "      <td>302.704106</td>\n",
              "      <td>8.643153</td>\n",
              "      <td>7.960070</td>\n",
              "      <td>6.971658</td>\n",
              "      <td>0.025224</td>\n",
              "      <td>1.038933</td>\n",
              "      <td>1.025350</td>\n",
              "      <td>22662.688857</td>\n",
              "      <td>1.229028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-30 16:00:00</th>\n",
              "      <td>311.84</td>\n",
              "      <td>313.03</td>\n",
              "      <td>305.18</td>\n",
              "      <td>305.25</td>\n",
              "      <td>20412.211</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>78500.0</td>\n",
              "      <td>65900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>302.822852</td>\n",
              "      <td>3.539632</td>\n",
              "      <td>3.170112</td>\n",
              "      <td>3.227502</td>\n",
              "      <td>-0.021258</td>\n",
              "      <td>1.025723</td>\n",
              "      <td>0.978867</td>\n",
              "      <td>15153.993714</td>\n",
              "      <td>1.346986</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-02 16:00:00</th>\n",
              "      <td>306.16</td>\n",
              "      <td>308.19</td>\n",
              "      <td>305.25</td>\n",
              "      <td>307.85</td>\n",
              "      <td>8655.593</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>29400.0</td>\n",
              "      <td>-16900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>302.482480</td>\n",
              "      <td>3.257401</td>\n",
              "      <td>3.267483</td>\n",
              "      <td>3.346529</td>\n",
              "      <td>0.005553</td>\n",
              "      <td>1.009631</td>\n",
              "      <td>1.005520</td>\n",
              "      <td>14375.985286</td>\n",
              "      <td>0.602087</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-03 16:00:00</th>\n",
              "      <td>307.82</td>\n",
              "      <td>308.11</td>\n",
              "      <td>305.45</td>\n",
              "      <td>306.53</td>\n",
              "      <td>7475.461</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>26600.0</td>\n",
              "      <td>12900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>302.648884</td>\n",
              "      <td>3.315941</td>\n",
              "      <td>3.273426</td>\n",
              "      <td>3.185222</td>\n",
              "      <td>-0.004288</td>\n",
              "      <td>1.008708</td>\n",
              "      <td>0.995809</td>\n",
              "      <td>14417.896429</td>\n",
              "      <td>0.518485</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-04 16:00:00</th>\n",
              "      <td>306.52</td>\n",
              "      <td>307.38</td>\n",
              "      <td>276.78</td>\n",
              "      <td>276.94</td>\n",
              "      <td>31075.859</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>306000.0</td>\n",
              "      <td>295800.0</td>\n",
              "      <td>...</td>\n",
              "      <td>291.618074</td>\n",
              "      <td>11.630279</td>\n",
              "      <td>8.843100</td>\n",
              "      <td>7.456650</td>\n",
              "      <td>-0.096532</td>\n",
              "      <td>1.110557</td>\n",
              "      <td>0.903497</td>\n",
              "      <td>15531.958000</td>\n",
              "      <td>2.000769</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-09 16:00:00</th>\n",
              "      <td>261.27</td>\n",
              "      <td>262.61</td>\n",
              "      <td>228.94</td>\n",
              "      <td>235.32</td>\n",
              "      <td>79202.195</td>\n",
              "      <td>13</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>336700.0</td>\n",
              "      <td>259500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>248.610364</td>\n",
              "      <td>21.923560</td>\n",
              "      <td>25.286724</td>\n",
              "      <td>22.517708</td>\n",
              "      <td>-0.099116</td>\n",
              "      <td>1.147069</td>\n",
              "      <td>0.900677</td>\n",
              "      <td>43547.316571</td>\n",
              "      <td>1.818762</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-06-30 16:00:00</th>\n",
              "      <td>235.48</td>\n",
              "      <td>248.64</td>\n",
              "      <td>234.81</td>\n",
              "      <td>247.33</td>\n",
              "      <td>35624.030</td>\n",
              "      <td>5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>138300.0</td>\n",
              "      <td>-118500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>228.333794</td>\n",
              "      <td>4.597713</td>\n",
              "      <td>5.577526</td>\n",
              "      <td>5.654892</td>\n",
              "      <td>0.050189</td>\n",
              "      <td>1.058899</td>\n",
              "      <td>1.050323</td>\n",
              "      <td>28889.284000</td>\n",
              "      <td>1.233123</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-02 16:00:00</th>\n",
              "      <td>246.03</td>\n",
              "      <td>254.55</td>\n",
              "      <td>243.31</td>\n",
              "      <td>249.44</td>\n",
              "      <td>38290.058</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>112400.0</td>\n",
              "      <td>-34100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>229.909323</td>\n",
              "      <td>6.730270</td>\n",
              "      <td>5.987682</td>\n",
              "      <td>5.695154</td>\n",
              "      <td>0.013736</td>\n",
              "      <td>1.046196</td>\n",
              "      <td>1.013860</td>\n",
              "      <td>30751.558000</td>\n",
              "      <td>1.245142</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-07-08 16:00:00</th>\n",
              "      <td>236.64</td>\n",
              "      <td>237.00</td>\n",
              "      <td>233.20</td>\n",
              "      <td>234.44</td>\n",
              "      <td>13506.295</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>38000.0</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>229.216933</td>\n",
              "      <td>5.306584</td>\n",
              "      <td>5.197092</td>\n",
              "      <td>5.323886</td>\n",
              "      <td>-0.009171</td>\n",
              "      <td>1.016295</td>\n",
              "      <td>0.990703</td>\n",
              "      <td>25013.456286</td>\n",
              "      <td>0.539961</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-09-19 16:00:00</th>\n",
              "      <td>218.32</td>\n",
              "      <td>218.52</td>\n",
              "      <td>214.80</td>\n",
              "      <td>215.89</td>\n",
              "      <td>9989.093</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37200.0</td>\n",
              "      <td>24300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>208.972044</td>\n",
              "      <td>2.697971</td>\n",
              "      <td>3.089528</td>\n",
              "      <td>2.970163</td>\n",
              "      <td>-0.010813</td>\n",
              "      <td>1.017318</td>\n",
              "      <td>0.988870</td>\n",
              "      <td>11478.403571</td>\n",
              "      <td>0.870251</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-21 16:00:00</th>\n",
              "      <td>214.25</td>\n",
              "      <td>216.70</td>\n",
              "      <td>213.60</td>\n",
              "      <td>214.21</td>\n",
              "      <td>18315.530</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>31000.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>...</td>\n",
              "      <td>204.299927</td>\n",
              "      <td>1.381530</td>\n",
              "      <td>3.346455</td>\n",
              "      <td>3.245658</td>\n",
              "      <td>-0.000233</td>\n",
              "      <td>1.014513</td>\n",
              "      <td>0.999813</td>\n",
              "      <td>18130.187571</td>\n",
              "      <td>1.010223</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-09 16:00:00</th>\n",
              "      <td>301.10</td>\n",
              "      <td>302.99</td>\n",
              "      <td>289.07</td>\n",
              "      <td>294.60</td>\n",
              "      <td>34026.908</td>\n",
              "      <td>-6</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>139200.0</td>\n",
              "      <td>65000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>264.837410</td>\n",
              "      <td>8.430595</td>\n",
              "      <td>8.996366</td>\n",
              "      <td>19.294613</td>\n",
              "      <td>-0.021652</td>\n",
              "      <td>1.048154</td>\n",
              "      <td>0.978412</td>\n",
              "      <td>43812.141286</td>\n",
              "      <td>0.776655</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-12 16:00:00</th>\n",
              "      <td>305.63</td>\n",
              "      <td>306.88</td>\n",
              "      <td>289.86</td>\n",
              "      <td>302.22</td>\n",
              "      <td>29153.177</td>\n",
              "      <td>-4</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>170200.0</td>\n",
              "      <td>34100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>281.964395</td>\n",
              "      <td>4.266991</td>\n",
              "      <td>7.063342</td>\n",
              "      <td>14.826511</td>\n",
              "      <td>-0.011222</td>\n",
              "      <td>1.058718</td>\n",
              "      <td>0.988843</td>\n",
              "      <td>36693.425143</td>\n",
              "      <td>0.794507</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-17 16:00:00</th>\n",
              "      <td>312.17</td>\n",
              "      <td>315.38</td>\n",
              "      <td>305.71</td>\n",
              "      <td>315.21</td>\n",
              "      <td>31396.007</td>\n",
              "      <td>-4</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>96700.0</td>\n",
              "      <td>-30400.0</td>\n",
              "      <td>...</td>\n",
              "      <td>295.866620</td>\n",
              "      <td>5.761918</td>\n",
              "      <td>6.451084</td>\n",
              "      <td>6.742311</td>\n",
              "      <td>0.009965</td>\n",
              "      <td>1.031631</td>\n",
              "      <td>1.009738</td>\n",
              "      <td>37302.934286</td>\n",
              "      <td>0.841650</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-20 16:00:00</th>\n",
              "      <td>314.06</td>\n",
              "      <td>319.47</td>\n",
              "      <td>313.90</td>\n",
              "      <td>318.62</td>\n",
              "      <td>13344.530</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>55700.0</td>\n",
              "      <td>-45600.0</td>\n",
              "      <td>...</td>\n",
              "      <td>295.930539</td>\n",
              "      <td>2.573414</td>\n",
              "      <td>7.148322</td>\n",
              "      <td>6.650086</td>\n",
              "      <td>0.014746</td>\n",
              "      <td>1.017745</td>\n",
              "      <td>1.014520</td>\n",
              "      <td>36134.023714</td>\n",
              "      <td>0.369307</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-29 16:00:00</th>\n",
              "      <td>308.48</td>\n",
              "      <td>313.02</td>\n",
              "      <td>307.51</td>\n",
              "      <td>309.19</td>\n",
              "      <td>22411.424</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>55100.0</td>\n",
              "      <td>-7100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>292.795870</td>\n",
              "      <td>6.515666</td>\n",
              "      <td>7.975152</td>\n",
              "      <td>7.610453</td>\n",
              "      <td>0.002237</td>\n",
              "      <td>1.017918</td>\n",
              "      <td>1.002302</td>\n",
              "      <td>29232.507286</td>\n",
              "      <td>0.766661</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-31 16:00:00</th>\n",
              "      <td>304.71</td>\n",
              "      <td>305.57</td>\n",
              "      <td>296.53</td>\n",
              "      <td>299.81</td>\n",
              "      <td>18862.881</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>90400.0</td>\n",
              "      <td>49000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>291.963475</td>\n",
              "      <td>3.244913</td>\n",
              "      <td>7.563010</td>\n",
              "      <td>7.288480</td>\n",
              "      <td>-0.016113</td>\n",
              "      <td>1.030486</td>\n",
              "      <td>0.983919</td>\n",
              "      <td>22701.072571</td>\n",
              "      <td>0.830925</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-02 16:00:00</th>\n",
              "      <td>302.56</td>\n",
              "      <td>303.73</td>\n",
              "      <td>299.71</td>\n",
              "      <td>300.46</td>\n",
              "      <td>9153.086</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>40200.0</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>291.499824</td>\n",
              "      <td>3.655351</td>\n",
              "      <td>6.914372</td>\n",
              "      <td>7.408047</td>\n",
              "      <td>-0.006974</td>\n",
              "      <td>1.013413</td>\n",
              "      <td>0.993059</td>\n",
              "      <td>17790.227714</td>\n",
              "      <td>0.514501</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-22 16:00:00</th>\n",
              "      <td>595.03</td>\n",
              "      <td>613.79</td>\n",
              "      <td>593.50</td>\n",
              "      <td>604.02</td>\n",
              "      <td>17078.807</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>202900.0</td>\n",
              "      <td>-89900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>525.734379</td>\n",
              "      <td>28.766667</td>\n",
              "      <td>29.558462</td>\n",
              "      <td>24.938808</td>\n",
              "      <td>0.015108</td>\n",
              "      <td>1.034187</td>\n",
              "      <td>1.015108</td>\n",
              "      <td>18825.813857</td>\n",
              "      <td>0.907202</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-14 16:00:00</th>\n",
              "      <td>569.76</td>\n",
              "      <td>582.31</td>\n",
              "      <td>561.50</td>\n",
              "      <td>579.96</td>\n",
              "      <td>7781.089</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>208100.0</td>\n",
              "      <td>-102000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>555.310155</td>\n",
              "      <td>9.982605</td>\n",
              "      <td>10.064557</td>\n",
              "      <td>15.474033</td>\n",
              "      <td>0.017867</td>\n",
              "      <td>1.037061</td>\n",
              "      <td>1.017902</td>\n",
              "      <td>6809.246429</td>\n",
              "      <td>1.142724</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-17 16:00:00</th>\n",
              "      <td>582.46</td>\n",
              "      <td>583.15</td>\n",
              "      <td>574.50</td>\n",
              "      <td>577.54</td>\n",
              "      <td>3321.004</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>86500.0</td>\n",
              "      <td>49200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>553.769727</td>\n",
              "      <td>11.051576</td>\n",
              "      <td>9.484157</td>\n",
              "      <td>14.427846</td>\n",
              "      <td>-0.008481</td>\n",
              "      <td>1.015057</td>\n",
              "      <td>0.991553</td>\n",
              "      <td>6193.464571</td>\n",
              "      <td>0.536211</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-18 16:00:00</th>\n",
              "      <td>577.58</td>\n",
              "      <td>581.64</td>\n",
              "      <td>575.00</td>\n",
              "      <td>577.58</td>\n",
              "      <td>3046.259</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>66400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>553.438731</td>\n",
              "      <td>9.108956</td>\n",
              "      <td>9.478934</td>\n",
              "      <td>13.628425</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>1.011548</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6187.932571</td>\n",
              "      <td>0.492290</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-19 16:00:00</th>\n",
              "      <td>577.56</td>\n",
              "      <td>580.03</td>\n",
              "      <td>569.12</td>\n",
              "      <td>576.65</td>\n",
              "      <td>3686.110</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>109100.0</td>\n",
              "      <td>9100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>555.791182</td>\n",
              "      <td>5.246773</td>\n",
              "      <td>9.619343</td>\n",
              "      <td>13.435367</td>\n",
              "      <td>-0.001610</td>\n",
              "      <td>1.019170</td>\n",
              "      <td>0.998424</td>\n",
              "      <td>5608.420857</td>\n",
              "      <td>0.657246</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-20 16:00:00</th>\n",
              "      <td>576.60</td>\n",
              "      <td>630.79</td>\n",
              "      <td>575.47</td>\n",
              "      <td>612.80</td>\n",
              "      <td>19410.165</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>553200.0</td>\n",
              "      <td>-362000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>561.787066</td>\n",
              "      <td>14.236625</td>\n",
              "      <td>12.117573</td>\n",
              "      <td>14.344317</td>\n",
              "      <td>0.062690</td>\n",
              "      <td>1.096130</td>\n",
              "      <td>1.062782</td>\n",
              "      <td>7305.472571</td>\n",
              "      <td>2.656935</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26 16:00:00</th>\n",
              "      <td>558.22</td>\n",
              "      <td>561.61</td>\n",
              "      <td>547.02</td>\n",
              "      <td>552.02</td>\n",
              "      <td>3006.269</td>\n",
              "      <td>-6</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>145900.0</td>\n",
              "      <td>62000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>487.296238</td>\n",
              "      <td>12.874500</td>\n",
              "      <td>21.624881</td>\n",
              "      <td>28.784586</td>\n",
              "      <td>-0.011426</td>\n",
              "      <td>1.026672</td>\n",
              "      <td>0.988893</td>\n",
              "      <td>3811.171000</td>\n",
              "      <td>0.788805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28 16:00:00</th>\n",
              "      <td>533.29</td>\n",
              "      <td>545.47</td>\n",
              "      <td>523.01</td>\n",
              "      <td>541.70</td>\n",
              "      <td>2418.163</td>\n",
              "      <td>-3</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>224600.0</td>\n",
              "      <td>-84100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>498.232380</td>\n",
              "      <td>18.816417</td>\n",
              "      <td>20.278528</td>\n",
              "      <td>24.018605</td>\n",
              "      <td>0.015656</td>\n",
              "      <td>1.042944</td>\n",
              "      <td>1.015770</td>\n",
              "      <td>3323.683857</td>\n",
              "      <td>0.727555</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-09-11 16:00:00</th>\n",
              "      <td>517.72</td>\n",
              "      <td>548.11</td>\n",
              "      <td>517.69</td>\n",
              "      <td>535.45</td>\n",
              "      <td>3914.348</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>304200.0</td>\n",
              "      <td>-177300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>476.244989</td>\n",
              "      <td>15.816497</td>\n",
              "      <td>14.338604</td>\n",
              "      <td>27.221710</td>\n",
              "      <td>0.033687</td>\n",
              "      <td>1.058761</td>\n",
              "      <td>1.034246</td>\n",
              "      <td>2531.869000</td>\n",
              "      <td>1.546031</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-09-12 16:00:00</th>\n",
              "      <td>535.44</td>\n",
              "      <td>554.21</td>\n",
              "      <td>534.90</td>\n",
              "      <td>553.69</td>\n",
              "      <td>3109.708</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>193100.0</td>\n",
              "      <td>-182500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>479.402212</td>\n",
              "      <td>21.672734</td>\n",
              "      <td>17.775524</td>\n",
              "      <td>25.217682</td>\n",
              "      <td>0.034065</td>\n",
              "      <td>1.036100</td>\n",
              "      <td>1.034084</td>\n",
              "      <td>2583.729714</td>\n",
              "      <td>1.203573</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-09-18 16:00:00</th>\n",
              "      <td>538.05</td>\n",
              "      <td>567.63</td>\n",
              "      <td>537.50</td>\n",
              "      <td>565.22</td>\n",
              "      <td>3829.966</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>301300.0</td>\n",
              "      <td>-271700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>480.737136</td>\n",
              "      <td>10.956573</td>\n",
              "      <td>25.732183</td>\n",
              "      <td>22.130592</td>\n",
              "      <td>0.050321</td>\n",
              "      <td>1.056056</td>\n",
              "      <td>1.050497</td>\n",
              "      <td>2632.266857</td>\n",
              "      <td>1.455007</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-10-05 16:00:00</th>\n",
              "      <td>564.08</td>\n",
              "      <td>569.00</td>\n",
              "      <td>558.01</td>\n",
              "      <td>567.50</td>\n",
              "      <td>1174.840</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>109900.0</td>\n",
              "      <td>-34200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>529.841146</td>\n",
              "      <td>10.796935</td>\n",
              "      <td>23.689185</td>\n",
              "      <td>23.817098</td>\n",
              "      <td>0.006045</td>\n",
              "      <td>1.019695</td>\n",
              "      <td>1.006063</td>\n",
              "      <td>2746.882143</td>\n",
              "      <td>0.427699</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-10-15 16:00:00</th>\n",
              "      <td>589.25</td>\n",
              "      <td>600.99</td>\n",
              "      <td>587.19</td>\n",
              "      <td>595.46</td>\n",
              "      <td>2595.866</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>138000.0</td>\n",
              "      <td>-62100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>539.852141</td>\n",
              "      <td>11.871401</td>\n",
              "      <td>14.352785</td>\n",
              "      <td>18.164364</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>1.023502</td>\n",
              "      <td>1.010539</td>\n",
              "      <td>2230.121429</td>\n",
              "      <td>1.164002</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-10-29 16:00:00</th>\n",
              "      <td>609.84</td>\n",
              "      <td>612.00</td>\n",
              "      <td>594.45</td>\n",
              "      <td>597.10</td>\n",
              "      <td>2891.387</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>175500.0</td>\n",
              "      <td>127400.0</td>\n",
              "      <td>...</td>\n",
              "      <td>568.986155</td>\n",
              "      <td>9.063669</td>\n",
              "      <td>7.902777</td>\n",
              "      <td>11.525641</td>\n",
              "      <td>-0.020891</td>\n",
              "      <td>1.029523</td>\n",
              "      <td>0.979109</td>\n",
              "      <td>2016.186857</td>\n",
              "      <td>1.434087</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-10-31 16:00:00</th>\n",
              "      <td>580.18</td>\n",
              "      <td>585.21</td>\n",
              "      <td>569.27</td>\n",
              "      <td>572.01</td>\n",
              "      <td>2827.593</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>159400.0</td>\n",
              "      <td>81700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>569.734268</td>\n",
              "      <td>12.502329</td>\n",
              "      <td>9.936301</td>\n",
              "      <td>10.434623</td>\n",
              "      <td>-0.014099</td>\n",
              "      <td>1.028001</td>\n",
              "      <td>0.985918</td>\n",
              "      <td>2277.333000</td>\n",
              "      <td>1.241625</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-11-04 16:00:00</th>\n",
              "      <td>559.70</td>\n",
              "      <td>569.84</td>\n",
              "      <td>544.00</td>\n",
              "      <td>564.25</td>\n",
              "      <td>3010.971</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>258400.0</td>\n",
              "      <td>-45500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>554.352682</td>\n",
              "      <td>14.828379</td>\n",
              "      <td>15.946364</td>\n",
              "      <td>15.248226</td>\n",
              "      <td>0.008075</td>\n",
              "      <td>1.047500</td>\n",
              "      <td>1.008129</td>\n",
              "      <td>2504.994857</td>\n",
              "      <td>1.201987</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-11-06 16:00:00</th>\n",
              "      <td>583.17</td>\n",
              "      <td>611.00</td>\n",
              "      <td>582.00</td>\n",
              "      <td>597.50</td>\n",
              "      <td>4616.260</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>290000.0</td>\n",
              "      <td>-143300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>554.231471</td>\n",
              "      <td>15.311957</td>\n",
              "      <td>16.309407</td>\n",
              "      <td>15.212357</td>\n",
              "      <td>0.024608</td>\n",
              "      <td>1.049828</td>\n",
              "      <td>1.024573</td>\n",
              "      <td>3288.258000</td>\n",
              "      <td>1.403862</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-09 16:00:00</th>\n",
              "      <td>696.93</td>\n",
              "      <td>698.70</td>\n",
              "      <td>675.76</td>\n",
              "      <td>693.10</td>\n",
              "      <td>2767.821</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>229400.0</td>\n",
              "      <td>38300.0</td>\n",
              "      <td>...</td>\n",
              "      <td>668.418313</td>\n",
              "      <td>11.646679</td>\n",
              "      <td>9.731789</td>\n",
              "      <td>17.074058</td>\n",
              "      <td>-0.005510</td>\n",
              "      <td>1.033947</td>\n",
              "      <td>0.994504</td>\n",
              "      <td>3317.385143</td>\n",
              "      <td>0.834338</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-01-13 16:00:00</th>\n",
              "      <td>677.29</td>\n",
              "      <td>698.23</td>\n",
              "      <td>666.49</td>\n",
              "      <td>695.17</td>\n",
              "      <td>2157.882</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>317400.0</td>\n",
              "      <td>-178800.0</td>\n",
              "      <td>...</td>\n",
              "      <td>678.635533</td>\n",
              "      <td>6.769370</td>\n",
              "      <td>11.549119</td>\n",
              "      <td>11.388156</td>\n",
              "      <td>0.026399</td>\n",
              "      <td>1.047623</td>\n",
              "      <td>1.026399</td>\n",
              "      <td>2831.503143</td>\n",
              "      <td>0.762098</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-04-20 16:00:00</th>\n",
              "      <td>588.17</td>\n",
              "      <td>608.51</td>\n",
              "      <td>587.50</td>\n",
              "      <td>604.06</td>\n",
              "      <td>1560.883</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>210100.0</td>\n",
              "      <td>-158900.0</td>\n",
              "      <td>...</td>\n",
              "      <td>556.110386</td>\n",
              "      <td>6.910518</td>\n",
              "      <td>12.931476</td>\n",
              "      <td>15.319416</td>\n",
              "      <td>0.026964</td>\n",
              "      <td>1.035762</td>\n",
              "      <td>1.027016</td>\n",
              "      <td>1511.546857</td>\n",
              "      <td>1.032640</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-04-21 16:00:00</th>\n",
              "      <td>604.03</td>\n",
              "      <td>612.20</td>\n",
              "      <td>594.50</td>\n",
              "      <td>609.78</td>\n",
              "      <td>3290.598</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>177000.0</td>\n",
              "      <td>-57500.0</td>\n",
              "      <td>...</td>\n",
              "      <td>555.505360</td>\n",
              "      <td>9.440189</td>\n",
              "      <td>12.600228</td>\n",
              "      <td>14.832490</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>1.029773</td>\n",
              "      <td>1.009519</td>\n",
              "      <td>1778.629857</td>\n",
              "      <td>1.850075</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-02 16:00:00</th>\n",
              "      <td>661.64</td>\n",
              "      <td>664.83</td>\n",
              "      <td>656.70</td>\n",
              "      <td>657.06</td>\n",
              "      <td>1559.197</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>81300.0</td>\n",
              "      <td>45800.0</td>\n",
              "      <td>...</td>\n",
              "      <td>620.076504</td>\n",
              "      <td>6.355826</td>\n",
              "      <td>13.891377</td>\n",
              "      <td>11.889614</td>\n",
              "      <td>-0.006922</td>\n",
              "      <td>1.012380</td>\n",
              "      <td>0.993078</td>\n",
              "      <td>1173.820857</td>\n",
              "      <td>1.328309</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55 rows × 176 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa30dbb6-f700-48b9-a77c-38023743f886')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa30dbb6-f700-48b9-a77c-38023743f886 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa30dbb6-f700-48b9-a77c-38023743f886');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6ff0ef6e-7344-4d5f-aa20-7f99c0012baa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ff0ef6e-7344-4d5f-aa20-7f99c0012baa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6ff0ef6e-7344-4d5f-aa20-7f99c0012baa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_data[TARGET_NAME].values, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQCKuo1tlPh7",
        "outputId": "fa406818-9d97-4529-8c16-aa0b17f1fe69"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[145,  20],\n",
              "       [  0,  35]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_fi = automl.get_feature_scores('fast')\n",
        "fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (30, 10), grid = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "aNDlsQ3nlL8L",
        "outputId": "0e446360-261e-4944-99ae-dcf5ad1f7e82"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Feature'>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pthm = '/content/drive/MyDrive/datasets/traders/'\n",
        "pthm = f'{pthm}model_{symbol}_{date}.pkl'\n",
        "with open(pthm, 'wb') as f:\n",
        "  pickle.dump(automl, f)\n",
        "\n",
        "pthm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kFrNsrSelZfU",
        "outputId": "e4288d0b-9a44-43f6-d794-4efa4599e7f2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/datasets/traders/model_BNB_USDT_2025-07-31.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = df[df['target']==1][-2:]\n",
        "tmp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "F8yuJeCIlyh0",
        "outputId": "1264c98d-5cb0-4757-eb6a-ce9219f6acd0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Open    High     Low   Close    Volume  diff  \\\n",
              "Date                                                                  \n",
              "2025-04-22 16:00:00  609.78  619.98  602.65  606.61  3580.150    -1   \n",
              "2025-07-02 16:00:00  661.64  664.83  656.70  657.06  1559.197    -1   \n",
              "\n",
              "                     diff_shift  target  diff_high_low  diff_open_close  ...  \\\n",
              "Date                                                                     ...   \n",
              "2025-04-22 16:00:00         0.0       1       173300.0          31700.0  ...   \n",
              "2025-07-02 16:00:00         0.0       1        81300.0          45800.0  ...   \n",
              "\n",
              "                       BB_upper    BB_lower  volatility_7  volatility_14  \\\n",
              "Date                                                                       \n",
              "2025-04-22 16:00:00  616.319515  554.899485      9.162739      11.013741   \n",
              "2025-07-02 16:00:00  668.143496  620.076504      6.355826      13.891377   \n",
              "\n",
              "                     volatility_21  daily_return  high_low_ratio  \\\n",
              "Date                                                               \n",
              "2025-04-22 16:00:00      14.966843     -0.005199        1.028756   \n",
              "2025-07-02 16:00:00      11.889614     -0.006922        1.012380   \n",
              "\n",
              "                     close_open_ratio  volume_ma_7  volume_ratio  \n",
              "Date                                                              \n",
              "2025-04-22 16:00:00          0.994801  2066.842429      1.732183  \n",
              "2025-07-02 16:00:00          0.993078  1173.820857      1.328309  \n",
              "\n",
              "[2 rows x 175 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e91e54e-128b-43ea-9a18-c7b04b49c087\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>diff</th>\n",
              "      <th>diff_shift</th>\n",
              "      <th>target</th>\n",
              "      <th>diff_high_low</th>\n",
              "      <th>diff_open_close</th>\n",
              "      <th>...</th>\n",
              "      <th>BB_upper</th>\n",
              "      <th>BB_lower</th>\n",
              "      <th>volatility_7</th>\n",
              "      <th>volatility_14</th>\n",
              "      <th>volatility_21</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>high_low_ratio</th>\n",
              "      <th>close_open_ratio</th>\n",
              "      <th>volume_ma_7</th>\n",
              "      <th>volume_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-04-22 16:00:00</th>\n",
              "      <td>609.78</td>\n",
              "      <td>619.98</td>\n",
              "      <td>602.65</td>\n",
              "      <td>606.61</td>\n",
              "      <td>3580.150</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>173300.0</td>\n",
              "      <td>31700.0</td>\n",
              "      <td>...</td>\n",
              "      <td>616.319515</td>\n",
              "      <td>554.899485</td>\n",
              "      <td>9.162739</td>\n",
              "      <td>11.013741</td>\n",
              "      <td>14.966843</td>\n",
              "      <td>-0.005199</td>\n",
              "      <td>1.028756</td>\n",
              "      <td>0.994801</td>\n",
              "      <td>2066.842429</td>\n",
              "      <td>1.732183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-07-02 16:00:00</th>\n",
              "      <td>661.64</td>\n",
              "      <td>664.83</td>\n",
              "      <td>656.70</td>\n",
              "      <td>657.06</td>\n",
              "      <td>1559.197</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>81300.0</td>\n",
              "      <td>45800.0</td>\n",
              "      <td>...</td>\n",
              "      <td>668.143496</td>\n",
              "      <td>620.076504</td>\n",
              "      <td>6.355826</td>\n",
              "      <td>13.891377</td>\n",
              "      <td>11.889614</td>\n",
              "      <td>-0.006922</td>\n",
              "      <td>1.012380</td>\n",
              "      <td>0.993078</td>\n",
              "      <td>1173.820857</td>\n",
              "      <td>1.328309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 175 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e91e54e-128b-43ea-9a18-c7b04b49c087')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e91e54e-128b-43ea-9a18-c7b04b49c087 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e91e54e-128b-43ea-9a18-c7b04b49c087');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cad6432e-b6f2-4ead-8042-6662f98025f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cad6432e-b6f2-4ead-8042-6662f98025f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cad6432e-b6f2-4ead-8042-6662f98025f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tmp"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "automl.predict(tmp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QCwLXY-w_Qa",
        "outputId": "31905188-37e9-4bf0-c35c-844806db57b8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84478366],\n",
              "       [0.2297642 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3wEetjtyWRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}